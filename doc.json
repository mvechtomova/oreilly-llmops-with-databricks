{
    "document": {
        "elements": [
            {
                "bbox": [
                    {
                        "coord": [
                            931,
                            49,
                            938,
                            60
                        ],
                        "page_id": 0
                    }
                ],
                "content": "1",
                "description": null,
                "id": 0,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            102,
                            938,
                            183
                        ],
                        "page_id": 0
                    }
                ],
                "content": "FLARE: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning",
                "description": null,
                "id": 1,
                "type": "title"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            199,
                            937,
                            240
                        ],
                        "page_id": 0
                    }
                ],
                "content": "Abolfazl Younesi* (Student, IEEE), Leon Kiss* Zahra Najafabadi Samani*, Juan Aznar Poveda*, Thomas\nFahringer* (Member, IEEE)",
                "description": null,
                "id": 2,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            315,
                            509,
                            828
                        ],
                        "page_id": 0
                    }
                ],
                "content": "Abstract—Federated learning (FL) enables collaborative model training while preserving data privacy. However, it remains vulnerable to malicious clients who compromise model integrity through Byzantine attacks, data poisoning, or adaptive adver- sarial behaviors. Existing defense mechanisms rely on static thresholds and binary classification, failing to adapt to evolving client behaviors in real-world deployments. We propose FLARE, an adaptive reputation-based framework that transforms client reliability assessment from binary decisions to a continuous, multi-dimensional trust evaluation. FLARE integrates: (i) a multi-dimensional reputation score capturing performance con- sistency, statistical anomaly indicators, and temporal behavior, (ii) a self-calibrating adaptive threshold mechanism that adjusts security strictness based on model convergence and recent attack intensity, (iii) reputation-weighted aggregation with soft exclusion to proportionally limit suspicious contributions rather than eliminating clients outright, and (iv) a Local Differential Privacy (LDP) mechanism enabling reputation scoring on privatized client updates. We further introduce a highly evasive Statistical Mimicry (SM) attack, a benchmark adversary that blends honest gradients with synthetic perturbations and persistent drift to remain undetected by traditional filters. Extensive experiments with 100 clients on MNIST, CIFAR-10, and SVHN demonstrate that FLARE maintains high model accuracy and converges faster than state-of-the-art Byzantine-robust methods under diverse attack types, including label flipping, gradient scaling, adaptive attacks, ALIE, and SM. FLARE improves robustness by up to 16% and preserves model convergence within 30% of the non-attacked baseline, while achieving strong malicious-client detection performance with minimal computational overhead.\nhttps://github.com/Anonymous0-paper/FLARE",
                "description": null,
                "id": 3,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            315,
                            947,
                            868
                        ],
                        "page_id": 0
                    }
                ],
                "content": "aggregates them into a global model [5]. This decentralized approach not only minimizes data exposure but also reduces the burden of data transfer and storage, making FL particularly suitable for large-scale, privacy-sensitive applications. The promise of FL lies in its ability to harness the collective intelligence of numerous devices while respecting individual privacy [6]–[8]. Despite its advantages, the distributed and open nature of FL introduces security and trust challenges. Unlike traditional centralized training, where the data and computation are under the control of a single trusted entity, FL operates in a loosely coordinated environment where clients are autonomous and often unverified [9], [10]. This autonomy creates opportunities for malicious or unreliable participants to inject harmful updates, skew the global model, or exploit the system for personal gain. The lack of direct oversight, combined with the diversity of hardware, network conditions, and user behaviors, further complicates the task of ensuring consistent and trustworthy collaboration. As an illustrative example, Figure 1 demonstrates how traditional static approaches to client reliability assessment can suffer from critical misclassification errors: they may permanently exclude honest clients experiencing transient network issues or possessing unique data distributions, while failing to detect sophisticated adaptive attackers who manipulate their behavior to evade detection. As FL deployments scale across thousands of geographically dispersed devices with varying trustworthiness, the need for robust, adaptive mechanisms to assess and manage client reliability becomes increasingly urgent.",
                "description": null,
                "id": 4,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            30,
                            367,
                            59,
                            949
                        ],
                        "page_id": 0
                    }
                ],
                "content": "V2: 1711/1651 [CS.LG] 1810/1825",
                "description": null,
                "id": 5,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            841,
                            500,
                            871
                        ],
                        "page_id": 0
                    }
                ],
                "content": "Index Terms—Federated learning, Reputation, Byzantine at-\ntacks, Client, Reliability, Trust management, Robust aggregation",
                "description": null,
                "id": 6,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            874,
                            938,
                            1109
                        ],
                        "page_id": 0
                    }
                ],
                "content": "Beyond adversarial behavior, unreliable client participation\nmay also arise from intermittent connectivity, volatile execu-\ntion environments, or heterogeneous device capabilities. Such\ninstability has been widely observed in distributed computing\nenvironments, cloud platforms, and intelligent edge systems,\nwhere node reliability cannot be assumed to remain static over\ntime and may fluctuate unpredictably under workload pressure\nor resource constraints. This observation is consistent with\nprior studies showing that dynamic availability and behavioral\nvariability affect the stability of large-scale distributed and\ncloud systems, necessitating adaptive mechanisms rather than\nfixed trust assumptions [11], [12] .",
                "description": null,
                "id": 7,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            225,
                            922,
                            355,
                            937
                        ],
                        "page_id": 0
                    }
                ],
                "content": "I. INTRODUCTION",
                "description": null,
                "id": 8,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            947,
                            510,
                            1124
                        ],
                        "page_id": 0
                    }
                ],
                "content": "Federated learning (FL) has emerged as a pivotal paradigm for training machine learning models across distributed de-\nvices while preserving data privacy [1–4]. By enabling\ncollaborative model training without centralizing raw data,\nFL addresses critical privacy concerns in domains ranging\nfrom healthcare to financial services. Participating clients in\nFL, such as smartphones, wearable devices, or edge servers,\nlocally compute model updates using their private data and\nsend only the updated parameters to a central server, which",
                "description": null,
                "id": 9,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1112,
                            947,
                            1246
                        ],
                        "page_id": 0
                    }
                ],
                "content": "Challenges. The challenge of identifying and mitigating unreliable clients in FL systems remains particularly acute due to three inherent characteristics of federated environments. First, the heterogeneity of client devices and data distributions makes it difficult to distinguish between legitimate statistical variations and adversarial behaviors [13], [14]. Second, the privacy-preserving nature of FL limits the server's visibility",
                "description": null,
                "id": 10,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1143,
                            500,
                            1186
                        ],
                        "page_id": 0
                    }
                ],
                "content": "Manuscript received XX May. 2025; revised XX Aug. 2025 and xx yy 202x; accepted xx yy 202x. Date of publication xx yy 202x; date of current version x June 202x. (Corresponding author: Abolfazl Younesi.)",
                "description": null,
                "id": 11,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1189,
                            500,
                            1246
                        ],
                        "page_id": 0
                    }
                ],
                "content": "A. Younesi, L. Kiss, Z. N. Samani, J. A. Poveda, and T. Fahringer are with the Department of Computer Science, University of Innsbruck, Innsbruck, Austria. E-mails: {Abolfazl.Younesi, Leon.Kiss, Zahra.Najafabadi-Samani, Juan.Aznar-Poveda, Thomas.Fahringer} @uibk.ac.at",
                "description": null,
                "id": 12,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            47,
                            937,
                            63
                        ],
                        "page_id": 1
                    }
                ],
                "content": "",
                "description": null,
                "id": 13,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            112,
                            115,
                            903,
                            324
                        ],
                        "page_id": 1
                    }
                ],
                "content": null,
                "description": "Two sets of line graphs, side-by-side, display fluctuating lines with green checkmarks indicating positive outcomes and red \"X\" marks showing negative results.",
                "id": 14,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            354,
                            937,
                            413
                        ],
                        "page_id": 1
                    }
                ],
                "content": "Fig. 1: Comparison of client reliability assessment approaches in federated learning. Left: Previous static methods make binary inclusion/exclusion decisions that remain fixed throughout training, leading to false positives for honest clients with temporary issues or unique data distributions, while failing to detect adaptive attackers. Right: Our FLARE framework uses dynamic reputation scoring with continuous weight adjustments, enabling nuanced trust assessments that adapt to evolving client behavior over time.",
                "description": null,
                "id": 15,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            451,
                            500,
                            548
                        ],
                        "page_id": 1
                    }
                ],
                "content": "into client operations, creating an information asymmetry that malicious actors can exploit [15], [16]. Third, the dynamic nature of real-world FL deployments, where clients may join, leave, or change their behavior patterns over time, renders static detection mechanisms ineffective [15], [17], [18].",
                "description": null,
                "id": 16,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            552,
                            500,
                            807
                        ],
                        "page_id": 1
                    }
                ],
                "content": "Existing approaches. Existing approaches to client reliability assessment in FL primarily fall into two categories: Byzantine-robust aggregation methods and client selection strategies [17]–[21]. Byzantine-robust aggregation techniques, such as Krum [21] and trimmed mean [19], attempt to minimize the impact of malicious updates through statistical filtering. While these methods provide theoretical guarantees under specific attack models, they often struggle with adaptive adversaries and can inadvertently exclude benign clients with unique data distributions. Client selection strategies, on the other hand, aim to identify trustworthy participants preemptively based on their historical performance or validation accuracy [22]–[24].",
                "description": null,
                "id": 17,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            812,
                            500,
                            987
                        ],
                        "page_id": 1
                    }
                ],
                "content": "Limitations. The existing approaches employ static thresh-\nolds and binary classification schemes that fail to capture\nthe nuanced and evolving nature of client reliability. These\nlimitations become particularly pronounced in dynamic FL en-\nvironments where client behaviors evolve over time [22], [23],\n[25]–[30]. A client that initially appears reliable may become\ncompromised or experience performance degradation, while\nsuspicious clients may prove trustworthy as more information\nbecomes available.",
                "description": null,
                "id": 18,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            991,
                            500,
                            1207
                        ],
                        "page_id": 1
                    }
                ],
                "content": "Furthermore, sophisticated adversaries can strategically ma-\nnipulate their behavior to evade detection, alternating between\nbenign and malicious actions to maintain acceptable aggregate\nmetrics while still degrading model performance. Existing\nmethods also suffer from three critical shortcomings [22]–\n[24], [26]–[33]: (i) they lack temporal awareness, treating each\nround independently without learning from historical patterns,\n(ii) they employ rigid decision boundaries that cannot adapt\nto varying attack intensities, and (iii) they fail to provide\ngraduated responses, resulting in either complete inclusion or\nexclusion of clients.",
                "description": null,
                "id": 19,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            1211,
                            500,
                            1246
                        ],
                        "page_id": 1
                    }
                ],
                "content": "Proposed approach. To address these challenges, we pro-\npose FLARE, a novel reputation-based framework for dynamic",
                "description": null,
                "id": 20,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            451,
                            937,
                            726
                        ],
                        "page_id": 1
                    }
                ],
                "content": "client reliability assessment in federated learning. FLARE fundamentally shifts from binary classification to continu-ous reputation scoring, enabling nuanced evaluation of client trustworthiness that adapts to behavioral changes over time. By maintaining multi-dimensional reputation profiles for each client, our system captures complex behavioral patterns that single-metric approaches miss. The framework operates on three core principles: (i) reputation accumulation through consistent benign behavior, (ii) graduated penalties for suspicious activities, and (iii) reputation-proportional influence on model aggregation. Moreover, our method introduces reputation-aware aggregation, which proportionally weighs client contributions based on their current trust levels, thereby achieving a balance between robustness and inclusivity.",
                "description": null,
                "id": 21,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            731,
                            937,
                            1006
                        ],
                        "page_id": 1
                    }
                ],
                "content": "Key insights. The key insight from Section IV driving our approach is that client reliability is not a static property, as shown in the Figure 1, but rather a dynamic characteristic that must be continuously assessed and updated. Through a combination of performance consistency metrics, statistical anomaly detection, and temporal behavior analysis, FLARE constructs reputation profiles that evolve with each training round. This dynamic assessment enables the system to quickly identify and isolate emerging threats while providing redemption pathways for temporarily unreliable clients. Additionally, we recognize that different phases of model training require different security postures. Early rounds benefit from diverse participation (see Algorithm 1), while later rounds demand stricter quality control.",
                "description": null,
                "id": 22,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            536,
                            1009,
                            910,
                            1025
                        ],
                        "page_id": 1
                    }
                ],
                "content": "Contributions. Our main contributions are as follows:",
                "description": null,
                "id": 23,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1031,
                            937,
                            1186
                        ],
                        "page_id": 1
                    }
                ],
                "content": "C1) Multi-Dimensional Dynamic Reputation Framework: We design a multi-dimensional reputation framework\nthat evaluates clients across behavioral, statistical, and tem-\nporal dimensions, providing comprehensive reliability assess-\nment beyond traditional single-metric approaches. Unlike ex-\nisting binary classification approaches, our framework main-\ntains continuous reputation scores that adapt to changing client\nbehavior, enabling reliability assessments.",
                "description": null,
                "id": 24,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1192,
                            937,
                            1246
                        ],
                        "page_id": 1
                    }
                ],
                "content": "C2) Adaptive Threshold Mechanism with Self-Calibration: We develop a self-calibrating threshold system that dynamically adjusts reliability criteria based on the global",
                "description": null,
                "id": 25,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            47,
                            937,
                            63
                        ],
                        "page_id": 2
                    }
                ],
                "content": "",
                "description": null,
                "id": 26,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            91,
                            500,
                            169
                        ],
                        "page_id": 2
                    }
                ],
                "content": "model's convergence state and historical attack patterns. This allows the system to become more stringent during critical training phases while remaining inclusive during exploration phases.",
                "description": null,
                "id": 27,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            175,
                            500,
                            292
                        ],
                        "page_id": 2
                    }
                ],
                "content": "C3) Reputation-Aware Aggregation with Soft Exclusion:\nWe propose reputation-aware aggregation with soft exclusion, where client contributions are weighted by their reputation scores rather than being accepted or rejected outright. This soft exclusion approach maintains diversity while minimizing the impact of potentially malicious updates.",
                "description": null,
                "id": 28,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            295,
                            500,
                            430
                        ],
                        "page_id": 2
                    }
                ],
                "content": "C4) Privacy-Preserving Reputation Assessment: We in-\ntegrate Local Differential Privacy (LDP) at the client side, en-\nsuring the server computes all reliability assessments only on\nnoisy, privatized updates. This addresses the privacy risk of an\n\"honest-but-curious\" server and explicitly manages the trade-\noff between privacy guarantees and the scoring mechanism's\nability to detect attacks.",
                "description": null,
                "id": 29,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            435,
                            500,
                            569
                        ],
                        "page_id": 2
                    }
                ],
                "content": "C5) Robust Evasive Attack Benchmark (SM Attack):\nWe design and implement the Statistical Mimicry (SM) at-\ntack[1] a challenging benchmark for sophisticated adversaries.\nThis attack (detailed in Table V) evades traditional filters by\ncreating a hybrid update that blends the client's honest gradient\nwith a synthetic sample and a small, persistent drift term\ndesigned to be undetectable in a single round.",
                "description": null,
                "id": 30,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            578,
                            500,
                            813
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Results. Extensive experiments including a hundred clients\nacross a real testbed on three benchmark datasets demonstrate\nthat FLARE achieves superior robustness against various at-\ntack vectors while maintaining faster convergence than ex-\nisting Byzantine-robust methods. Our framework successfully\nidentifies and mitigates both static and adaptive adversaries,\nincreasing robustness against attack success rates by up to\n16% compared to baseline approaches, while preserving model\nconvergence within 30% of the baseline. Furthermore, our\nsystem demonstrates adaptability, maintaining performance\nacross varying attack intensities (5%-30% malicious clients)\nand attack types.",
                "description": null,
                "id": 31,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            819,
                            500,
                            953
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Paper organization. The remainder of this paper is orga-\nnized as follows: Section II reviews related work in Byzantine-\nrobust FL and reputation systems. Section III presents the\nFLARE framework, including our threat model and reputation\nscoring mechanisms. Section IV describes our experimental\nevaluation and comparative analysis. Section V concludes with\na discussion of future work.",
                "description": null,
                "id": 32,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            217,
                            987,
                            364,
                            1000
                        ],
                        "page_id": 2
                    }
                ],
                "content": "II. RELATED WORK",
                "description": null,
                "id": 33,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            1015,
                            500,
                            1210
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Defenses against malicious clients in FL are numerous, but they can be broadly categorized into three main approaches:\n(i) robust aggregation mechanisms that statistically minimize the impact of outliers, (ii) per-round detection and filtering systems that aim to identify and remove malicious updates, and (iii) reputation-based systems that use client history to guide selection. We argue that while these methods are ef-fective against simple attacks, they often fail to address the dual challenge of sophisticated, adaptive adversaries and the preservation of benign, non-IID clients.",
                "description": null,
                "id": 34,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            97,
                            1233,
                            427,
                            1246
                        ],
                        "page_id": 2
                    }
                ],
                "content": "See the supplementary material Section III for Pseudo code",
                "description": null,
                "id": 35,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            96,
                            764,
                            110
                        ],
                        "page_id": 2
                    }
                ],
                "content": "A. Robust Aggregation Mechanisms",
                "description": null,
                "id": 36,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            121,
                            937,
                            295
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Robust aggregation methods aim to statistically limit the\nimpact of malicious updates, often without identifying the spe-\ncific source. These include coordinate-wise approaches such as\nthe trimmed mean [19] and the median, as well as geometric\nmethods such as Krum [21] . More advanced techniques, such\nas MCA [34] , use maximum correntropy to handle heavy-\ntailed noise, while others [39] combine local estimation with\nglobal aggregation. Clustering-based approaches, like that of\nSattler et al. [40] , treat the largest client cluster as benign.",
                "description": null,
                "id": 37,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            301,
                            937,
                            476
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Limitations: The primary weakness of these static ap-\nproaches is their assumption that malicious updates are sta-\ntistical outliers. This makes them vulnerable to sophisticated\nmimicry attacks (such as ALIE [41] or our SM benchmark)\nthat are specifically designed to appear statistically similar\nto benign updates. Furthermore, in highly non-IID settings,\nthese methods can incorrectly penalize benign clients who\nhold unique or rare data, as their valid updates may appear\nas statistical anomalies, as illustrated in Figure 1.",
                "description": null,
                "id": 38,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            502,
                            779,
                            517
                        ],
                        "page_id": 2
                    }
                ],
                "content": "B. Per-Round Detection and Filtering",
                "description": null,
                "id": 39,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            527,
                            937,
                            661
                        ],
                        "page_id": 2
                    }
                ],
                "content": "A second category of defenses attempts to detect and filter malicious clients on a per-round basis. SHERPA [37] leverages\nexplainable AI (XAI) to cluster SHAP attributions, identifying\nclients with anomalous feature importance patterns. FedDMC [35] uses PCA and tree-based clustering on model parameters\nto find outliers. FedID [36] analyzes gradients to maintain\ndynamic scores for detecting backdoor attacks.",
                "description": null,
                "id": 40,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            666,
                            937,
                            781
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Limitations: These methods are often computationally expensive (e.g., SHERPA [37] relies on SHAP) or are designed for specific attack vectors (e.g., backdoors). More importantly, because they are largely stateless and operate per round, they are susceptible to adaptive attackers who behave benignly for several rounds to evade detection before attacking.",
                "description": null,
                "id": 41,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            807,
                            819,
                            824
                        ],
                        "page_id": 2
                    }
                ],
                "content": "C. Reputation and Client Selection Systems",
                "description": null,
                "id": 42,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            834,
                            937,
                            1187
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Reputation-based systems, which are the closest to our work, address the temporal gap by incorporating client history. Penalva et al. [27] and Guo et al. [1] propose reputation systems for decentralized and vehicular networks, respectively. In the hierarchical FL (HFL) setting, some works use reputation to guide client selection, such as the DRL-based approach by Al-Maslamani et al. [29] and the stochastic programming method by Tan et al. [28] , which balances reputation with cost. Similar forms of reliability modeling have also been explored in distributed computing and fog-based industrial systems, where execution correctness depends on continuously estimating node stability and resource trustworthiness rather than binary inclusion policies. Notably, recent work in fog-integrated smart factories demonstrates that reliability-aware system design improves resilience under fluctuating execution conditions and partially unreliable participants [42] . These findings conceptually reinforce the need for adaptive trust adjustment rather than static acceptance or rejection rules.",
                "description": null,
                "id": 43,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1192,
                            937,
                            1246
                        ],
                        "page_id": 2
                    }
                ],
                "content": "Limitations: While these systems correctly identify history as a key factor, their application is often limited. Many focus on using reputation for binary selection [28], [29] rather than",
                "description": null,
                "id": 44,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            47,
                            937,
                            63
                        ],
                        "page_id": 3
                    }
                ],
                "content": "",
                "description": null,
                "id": 45,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            286,
                            88,
                            733,
                            102
                        ],
                        "page_id": 3
                    }
                ],
                "content": "TABLE I: Comprehensive Comparison of Robust / Privacy-Preserving FL Works",
                "description": null,
                "id": 46,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            102,
                            937,
                            320
                        ],
                        "page_id": 3
                    }
                ],
                "content": "<table><thead><tr><td><b>Reference</b></td><td><b>FL</b></td><td><b>Setting</b></td><td><b>Defense / Method Type</b></td><td><b>Attacks</b></td><td><b>Addressed</b></td><td><b>Privacy</b></td><td><b>Adaptive</b></td><td><b>Limitations / Notes</b></td></tr></thead><tbody><tr><td>MCA [54]</td><td></td><td>HFL</td><td>Robust aggregation (stat.)</td><td>Byzantine, sign-flip, ALIE</td><td>×</td><td></td><td>Static rule</td><td>Strong on IID; less on non-IID, tuning kernel width needed.</td></tr><tr><td>FedDMC [38]</td><td></td><td>HFL</td><td>Detection + filtering</td><td>Byzantine/poisoning variants</td><td>×</td><td></td><td>Partly (EMA history)</td><td>May remove rare benigns, assumes access to updates.</td></tr><tr><td>FedID [36]</td><td></td><td>HFL</td><td>Multi-metric scoring</td><td>Backdoor incl. edge-case PGD</td><td>×</td><td>Yes</td><td>dynamic weights</td><td>Focused on backdoors, heavy metric tuning; in high-dim.</td></tr><tr><td>SHERPA [57]</td><td></td><td>HFL</td><td>Explainable detection</td><td>Data/model poisoning</td><td>DP (optional)</td><td>Partly (cumulative)</td><td></td><td>Higher compute, SHAP variance under non-IID</td></tr><tr><td>DDFed [38]</td><td></td><td>HFL</td><td>Privacy+robustness</td><td>Model poisoning, Byzantine</td><td>FHE</td><td>Moderate (feedback)</td><td></td><td>Crypto overhead, slower aggregation, topology intact.</td></tr><tr><td>Label Inference Attacks</td><td>VFL [30]</td><td>VFL</td><td>Attack paper</td><td>Label inference</td><td>×</td><td>N/A</td><td></td><td>Shows severe VFL label leakage; defenses not fully effective.</td></tr><tr><td>MADDPG Reputation (HFL/VFL) [29]</td><td>HFL</td><td>Reputation + DRL selection</td><td>Poisoning, unreachable updates</td><td>×</td><td>Yes (RL policy)</td><td></td><td>RL overreach, policy training stability.</td></tr><tr><td>SCS (Reputation-aware SIP) [28]</td><td>HFL</td><td>Opt. client selection</td><td>Misbehavior risk</td><td>×</td><td></td><td>Via re-optimizing</td><td>Focus on hire cost/fairness, storage/elimination needs.</td></tr><tr><td>RepoNet (HFL) [31]</td><td>DFL</td><td>Reputation + weighting</td><td>Poisoning, delay, flooding</td><td>×</td><td>Yes (progressive penalization)</td><td></td><td>No blockchain, local metrics may be noisy in large graphs.</td></tr><tr><td>RSFFL for IoV [25]</td><td>HFL</td><td>Fair and secure reputation</td><td>Malicious clients</td><td>×</td><td></td><td>Periodic updates</td><td>Adds compression pipeline, IoV comms constraints.</td></tr><tr><td>FLARE (Ours)</td><td>HFL</td><td>Dynamic reputation + soft exclusion</td><td>Byzantine, adaptive, scaling, fault-free, evasive (SM)</td><td>LDP (client-side)</td><td>Yes (continuous evaluation)</td><td></td><td>Hyperparameters (decay/recovery)</td></tr></tbody></table>",
                "description": null,
                "id": 47,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            359,
                            510,
                            576
                        ],
                        "page_id": 3
                    }
                ],
                "content": "for continuous contribution weighting, thereby still risking the exclusion of clients who are partially reliable. Those that do use weighting (e.g., RepuNet [27]) often rely on a single, time-decayed score and are designed for DFL, making them sensitive to collusion and metric noise. To our knowledge, no existing work provides a holistic HFL framework that combines a multi-dimensional reputation score (integrating performance, statistical, and temporal data), a dynamically weighted aggregation of these scores, and an adaptive security threshold that adjusts itself based on the global model's convergence state.",
                "description": null,
                "id": 48,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            607,
                            355,
                            622
                        ],
                        "page_id": 3
                    }
                ],
                "content": "D. Other Defenses and Attack Analyses",
                "description": null,
                "id": 49,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            632,
                            510,
                            807
                        ],
                        "page_id": 3
                    }
                ],
                "content": "A final category of work addresses related but orthogonal challenges. Several works analyze specific attack vectors, such\nas label leakage in VFL [30] or poisoning against robust\naggregators [43] . Other defenses integrate cryptographic or\nblockchain-based solutions, such as DDFed [38], Zeng et al.\n[44] , and Kasyap and Tripathy [45] , but these incur significant\ncomputational and communication overhead. Works like Gu\net al. [46] and Jiang et al. [47] focus on the important, but\nseparate, problems of DP-robustness and fair selection.",
                "description": null,
                "id": 50,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            812,
                            510,
                            927
                        ],
                        "page_id": 3
                    }
                ],
                "content": "Limitations: While valuable, these methods do not provide a comprehensive, lightweight, and adaptive framework for managing dynamic client reliability. Cryptographic methods are often too slow for large-scale, real-time FL, while other defenses solve for different objectives rather than the core challenge of adaptive, multi-faceted malicious behavior.",
                "description": null,
                "id": 51,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            956,
                            281,
                            974
                        ],
                        "page_id": 3
                    }
                ],
                "content": "E. Positioning Our Approach",
                "description": null,
                "id": 52,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            983,
                            501,
                            1120
                        ],
                        "page_id": 3
                    }
                ],
                "content": "In contrast to these prior works, FLARE is designed as a complete and practical framework. It addresses the gaps by: (1) replacing binary rejection with \"soft exclusion\" (reputation-weighted aggregation) to preserve benign non-IID clients. (2) Integrating a multi-dimensional score that captures perfor-mance, statistical, and temporal behaviors to defeat simple evasion.",
                "description": null,
                "id": 53,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            197,
                            1148,
                            384,
                            1161
                        ],
                        "page_id": 3
                    }
                ],
                "content": "III. FLARE FRAMEWORK",
                "description": null,
                "id": 54,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1171,
                            501,
                            1246
                        ],
                        "page_id": 3
                    }
                ],
                "content": "In this section, we present the FLARE framework for dynamic client reliability assessment in FL (see Figure 2 ). We first describe our system and threat models, then detail our multi-dimensional reputation scoring mechanism, followed by",
                "description": null,
                "id": 55,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            558,
                            355,
                            897,
                            824
                        ],
                        "page_id": 3
                    }
                ],
                "content": null,
                "description": "A diagram illustrates a multi-dimensional reputation scoring process with labeled boxes and arrows outlining steps from performance analysis to client aggregation.",
                "id": 56,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            831,
                            947,
                            937
                        ],
                        "page_id": 3
                    }
                ],
                "content": "Fig. 2: Our proposed 5-step framework for reputation-aware aggregation:\n(1) Compute per-client performance scores, (2) Dynamically adjust mixing coefficients $w_i^t$ based on convergence progress and detected attack patterns.\n(3) Compute a weighted reputation score for each client using $w_i^t$ . (4) Classify clients into trusted (fully included), suspicious (partially included), or untrusted (excluded), (5) Perform aggregation via weighted FedAvg using reputation-based client inclusion.",
                "description": null,
                "id": 57,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            955,
                            937,
                            1011
                        ],
                        "page_id": 3
                    }
                ],
                "content": "the dynamic reliability assessment algorithm and reputation-weighted aggregation scheme. The main symbols and parameters used throughout this section are summarized in Table II",
                "description": null,
                "id": 58,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1059,
                            765,
                            1075
                        ],
                        "page_id": 3
                    }
                ],
                "content": "A. System Model and Threat Model",
                "description": null,
                "id": 59,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1090,
                            947,
                            1248
                        ],
                        "page_id": 3
                    }
                ],
                "content": "System model. We consider a standard FL setting with a central server $S$ and $N$ clients $C=\\{c_1, c_2, \\ldots, c_N\\}$ . In each communication round $t$ , the server selects a subset of clients $C_t \\subseteq C$ to participate in training. Each selected client $c_i$ receives the current global model $w^t$ , performs local training on its private dataset $D_i$ , and sends back the model update $\\Delta u_i^t = w_i^t - w^t$ to the server. The server then aggregates these updates to produce the new global model $w^{t+1}$ .",
                "description": null,
                "id": 60,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            41,
                            937,
                            53
                        ],
                        "page_id": 4
                    }
                ],
                "content": "",
                "description": null,
                "id": 61,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            194,
                            88,
                            386,
                            102
                        ],
                        "page_id": 4
                    }
                ],
                "content": "TABLE II: Summary of Notations",
                "description": null,
                "id": 62,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            102,
                            500,
                            340
                        ],
                        "page_id": 4
                    }
                ],
                "content": "<table><thead><tr><td><b>Notation</b></td><td><b>Description</b></td></tr></thead><tbody><tr><td>System Parameters</td><td></td></tr><tr><td><i>N</i>, <i>K</i>, <i>T</i>, <i>t</i></td><td>Total clients, selected clients per round, total rounds, and current round index.</td></tr><tr><td><i>C</i>, <i>S</i><sup>1</sup>, <i>M</i>, <i>B</i></td><td>All clients, selected clients, malicious clients, and benign clients.</td></tr><tr><td>Model Parameters</td><td></td></tr><tr><td><b>w</b><sup><b>i</b></sup>, <b>w</b><sup><b>i</b></sup><sub>Δ</sub><sup><b>t</b></sup></td><td>Global model, local model, and update from client <i>i</i> at round <i>t</i>.</td></tr><tr><td><i>D</i><sub><i>i</i></sub>, <i>n</i><sub><i>i</i></sub></td><td>Dataset and number of samples of client <i>i</i>.</td></tr><tr><td><i>L</i>, <i>η</i></td><td>Loss function and learning rate.</td></tr><tr><td>Reputation System</td><td></td></tr><tr><td><i>r</i><sup><i>i</i></sup>, <b>R</b><sup><i>i</i></sup>, <i>σ</i><sup><i>i</i></sup></td><td>Reputation score, vector, and aggregation weight at round <i>t</i>.</td></tr><tr><td><i>θ</i><sup><i>i</i></sup>, <i>τ</i><sub>min</sub>, <i>τ</i><sub>max</sub></td><td>Adaptive threshold and its bounds.</td></tr><tr><td><i>γ</i>, <i>β</i></td><td>Reputation decay and recovery rates.</td></tr><tr><td>Behavioral Metrics</td><td></td></tr><tr><td><i>m</i><sup><i>i</i></sup>, <i>d</i><sup><i>i</i></sup>, <i>σ</i><sup><i>i</i></sup>, <i>ρ</i><sup><i>i</i></sup></td><td>Metric vector, distance, anomaly, and consistency scores for client <i>i</i>.</td></tr><tr><td><i>H</i><sub><i>i</i></sub>, <i>W</i></td><td>Historical behavior window and its size.</td></tr><tr><td>Privacy-Preserving Components</td><td></td></tr><tr><td><i>e</i><sub><i>i</i></sub>, <i>V</i></td><td>Zero-knowledge proof and its verification function.</td></tr><tr><td><i>δ</i></td><td>Differential privacy budget and parameter.</td></tr><tr><td>Attack Parameters</td><td></td></tr><tr><td><i>f</i>, <i>P</i><sub><i>i</i></sub>, <i>ν</i>, <i>δ</i></td><td>Fraction of malicious clients, attack pattern, intensity, and frequency.</td></tr></tbody></table>",
                "description": null,
                "id": 63,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            355,
                            509,
                            631
                        ],
                        "page_id": 4
                    }
                ],
                "content": "Threat model. Similar to the related works [48–52] , we\nassume that up to $f<N/2$ clients can be malicious or\nunreliable, exhibiting various attack behaviors including: (i)\nByzantine attacks where clients send arbitrary model updates,\n(ii) Data poisoning where clients train on corrupted labels,\n(iii) Model poisoning where clients manipulate gradients to\ndegrade performance, (iv) Adaptive attacks where clients al-\nternate between benign and malicious behavior to evade de-\ntection, and (v) Statistical mimicry attacks[53] where adversaries\ncraft updates that imitate the statistical profile of honest clients\nto bypass robust aggregation. We assume the server is honest\nbut curious [53] and has limited visibility into client operations\ndue to privacy constraints. Clients cannot forge identities but\nmay collude to coordinate attacks.",
                "description": null,
                "id": 64,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            661,
                            362,
                            678
                        ],
                        "page_id": 4
                    }
                ],
                "content": "B. Multi-dimensional Reputation Scoring",
                "description": null,
                "id": 65,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            688,
                            510,
                            865
                        ],
                        "page_id": 4
                    }
                ],
                "content": "The core innovation of FLARE lies in its comprehensive reputation scoring system, which evaluates clients across multiple behavioral dimensions (see Figure 2 (1) ). For each client $c_i$ , we maintain a reputation vector $R_{i,t}^t = [r_{i,1}^t, r_{i,2}^t, r_{i,3}^t]$ at round $t$ , where each component captures different reliability aspects. Figure 3 illustrates typical trajectories of the three evidence scores $(r_1, r_2, r_3)$ , the combined reputation $R_t$ , the adaptive threshold $\\Theta^t$ , and the resulting weight $w_t$ for benign, noisy-but-benign, and malicious clients.",
                "description": null,
                "id": 66,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            865,
                            510,
                            1064
                        ],
                        "page_id": 4
                    }
                ],
                "content": "Performance consistency score (r_(i,1)). This metric evaluates the consistency of a client's model updates over time. The intuition is that benign clients will consistently provide updates that align with the model's general convergence trajectory, while a sudden compromise or attack will result in a significant directional deviation. This score is designed to capture such deviations, particularly those that may be subtle (such as label flipping) but consistently harm progress. We compute the cosine similarity between the current update and the moving average of past benign updates:",
                "description": null,
                "id": 67,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            134,
                            1074,
                            500,
                            1111
                        ],
                        "page_id": 4
                    }
                ],
                "content": "r _ { i , 1 } ^ { t } = \\alpha \\cdot r _ { i , 1 } ^ { t - 1 } + ( 1 - \\alpha ) \\cdot \\mathrm { c o s } ( \\triangle u _ { i } ^ { t } , \\bar { \\triangle } w _ { i } ^ { t - 1 } ) \\tag{1}",
                "description": null,
                "id": 68,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            1117,
                            500,
                            1152
                        ],
                        "page_id": 4
                    }
                ],
                "content": "where $\\Delta u_i$ represents the exponential moving average of\nclient $i$ 's historical updates, and $\\alpha \\in [0,1]$ is the decay factor.",
                "description": null,
                "id": 69,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            1152,
                            500,
                            1212
                        ],
                        "page_id": 4
                    }
                ],
                "content": "Statistical anomaly score (r<sub>t,2</sub>). This score employs statistical outlier detection to identify updates that significantly deviate from the distribution of all client updates in round t.",
                "description": null,
                "id": 70,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            91,
                            1233,
                            312,
                            1246
                        ],
                        "page_id": 4
                    }
                ],
                "content": "See supplementary material Section III",
                "description": null,
                "id": 71,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            97,
                            937,
                            190
                        ],
                        "page_id": 4
                    }
                ],
                "content": "It is designed to capture gross anomalies, such as Byzantine gradient noise or significant gradient scaling attacks, by iden-\ntifying updates that are statistically improbable relative to the\ncurrent round's submissions. We use the Mahalanobis distance\nfor this:",
                "description": null,
                "id": 72,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            601,
                            199,
                            937,
                            240
                        ],
                        "page_id": 4
                    }
                ],
                "content": "d_{i}^{t}=\\sqrt{(\\Delta w_{i}^{t}-\\mu^{t})T\\Sigma^{-1}(\\Delta w_{i}^{t}-\\mu^{t})}",
                "description": null,
                "id": 73,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            236,
                            937,
                            392
                        ],
                        "page_id": 4
                    }
                ],
                "content": "where $\\mu^t$ is the mean of all updates in round $t$ . Given that\ncomputing the full $d\\times d$ covariance matrix $\\Sigma$ (and its inverse) is\ncomputationally infeasible for large models, we employ a diag-\nonal covariance approximation. $\\Sigma$ is thus treated as a vector of\nparameter-wise variances, making $\\Sigma^{-1}$ a simple element-wise\nreciprocal. This reduces the calculation to a highly efficient,\nstandardized Euclidean distance that effectively detects gross\nstatistical outliers[5]. The anomaly score is then:",
                "description": null,
                "id": 74,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            593,
                            399,
                            937,
                            454
                        ],
                        "page_id": 4
                    }
                ],
                "content": "r_{i,2}^t = \\left\\{ \\begin{array} { l l } { 1 } & { \\mathrm { i f ~ } d _ { i } ^ { t } \\leq \\tau _ { d } } \\\\ { \\mathrm { e x p } ( - \\lambda ( d _ { i } ^ { t } - \\tau _ { d } ) ) } & { \\mathrm { i f ~ } d _ { i } ^ { t } > \\tau _ { d } } \\\\ \\end{array} \\right. \\tag{3}",
                "description": null,
                "id": 75,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            457,
                            937,
                            494
                        ],
                        "page_id": 4
                    }
                ],
                "content": "where $\\tau_d$ is the anomaly threshold and $\\lambda$ controls the penalty severity.",
                "description": null,
                "id": 76,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            510,
                            897,
                            547
                        ],
                        "page_id": 4
                    }
                ],
                "content": "Algorithm 1: Dynamic Weight Computation for Rep-utation Scoring",
                "description": null,
                "id": 77,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            555,
                            921,
                            1143
                        ],
                        "page_id": 4
                    }
                ],
                "content": "<table><tr><th colspan=\"2\">Input: Reputation components (ri,t) for all i ∈ Ct and j ∈ {1,2,3}.</th></tr><tr><td>Output: Adaptive weights w^(t) = [w^(t), w^(t), w^(t)]</td></tr><tr><td>1 for j = 1 to 3 do</td></tr><tr><td>2</td><td>var( {ri,t : i ∈ C(t)} ) / λ calculate variance across clients * /</td></tr><tr><td>3</td><td>Identify suspicious historical patterns</td></tr><tr><td>4</td><td>St { i ∈ Ct : Ri,t < θ +1 / 2}</td></tr><tr><td>5</td><td>Compute separation between benign and suspicious</td></tr><tr><td>6</td><td>mean( {ri,t : i ∉ St} )</td></tr><tr><td>7</td><td>μsus ← mean( {ri,t : i ∈ St} )</td></tr><tr><td>8</td><td>sep(t) ← [μsus - μbenign] / μsus</td></tr><tr><td>9</td><td>nj ← var( sep) / λ Calculate discriminative power * /</td></tr><tr><td>10</td><td>Adjust for model convergence state</td></tr><tr><td>11</td><td>if conv(t) > 0.7 then:</td></tr><tr><td>12</td><td>// Late training: prioritize consistency</td></tr><tr><td>13</td><td>nj ← nj / 1.5</td></tr><tr><td>14</td><td>nj3 ← nj3 / 1.2</td></tr><tr><td>15</td><td>else</td></tr><tr><td>16</td><td>// Early training: prioritize anomaly detection</td></tr><tr><td>17</td><td>nj2 ← nj2 / 1.3</td></tr><tr><td>18</td><td>nj1 ← nj1 / 0.8</td></tr><tr><td>19</td><td>// Detect predominant attack pattern from history</td></tr><tr><td>20</td><td>attack_pattern ← ANALYZEPATTERN(H^(t-1))</td></tr><tr><td>21</td><td>// switch attack pattern do</td></tr><tr><td>22</td><td>case gradient_scaling do</td></tr><tr><td>23</td><td>nj2 ← nj2 / 2.0</td></tr><tr><td>24</td><td>// Boost anomaly detection</td></tr><tr><td>25</td><td>case adaptive_attack do</td></tr><tr><td>26</td><td>nj3 ← nj3 / 2.0</td></tr><tr><td>27</td><td>// Boost temporal analysis</td></tr><tr><td>28</td><td>case label_flipping do</td></tr><tr><td>29</td><td>nj1 ← nj1 / 1.8</td></tr><tr><td>30</td><td>// Boost consistency check</td></tr><tr><td>31</td><td>Normalize weights using softmax</td></tr><tr><td>32</td><td>for j = 1 to 3 do</td></tr><tr><td>33</td><td>exp(nj)</td></tr><tr><td>34</td><td>w^(t) ← Σ3 k=1 exp(njk)</td></tr><tr><td>35</td><td>// Apply smoothing to prevent abrupt changes</td></tr><tr><td>36</td><td>if t > 1 then</td></tr><tr><td>37</td><td>for j = 1 to 3 do</td></tr><tr><td>38</td><td>w^(t) ← 0.7 * w^(t-1) + 0.3 * w^(t)</td></tr><tr><td>39</td><td>return w^(t)</td></tr></table>",
                "description": null,
                "id": 78,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1164,
                            937,
                            1202
                        ],
                        "page_id": 4
                    }
                ],
                "content": "Temporal behavior score (r<sub>i,3</sub><sup>t</sup>). This component tracks\na client's meta-behavior, such as participation patterns and",
                "description": null,
                "id": 79,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1217,
                            937,
                            1246
                        ],
                        "page_id": 4
                    }
                ],
                "content": "See Supplementary Material Section II-A for the incremental update algorithm used to estimate these variances",
                "description": null,
                "id": 80,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            47,
                            937,
                            63
                        ],
                        "page_id": 5
                    }
                ],
                "content": "",
                "description": null,
                "id": 81,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            97,
                            500,
                            192
                        ],
                        "page_id": 5
                    }
                ],
                "content": "response times. Its purpose is to penalize unreliable clients (e.g., 'free-riders' who rarely participate) or those with erratic network behavior (high response time variance). Both of these behaviors can degrade training stability and may signal an intermittent or adaptive attacker attempting to evade detection.",
                "description": null,
                "id": 82,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            171,
                            202,
                            500,
                            240
                        ],
                        "page_id": 5
                    }
                ],
                "content": "r_{i,3}^t = \\beta \\cdot p_i^t + (1 - \\beta) \\cdot \\frac{1}{1 + \\sigma_{RT,i}} \\tag{4}",
                "description": null,
                "id": 83,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            252,
                            500,
                            429
                        ],
                        "page_id": 5
                    }
                ],
                "content": "where $p_t^t$ is the participation rate over the last $k$ rounds, $\\sigma_{RT,i}$ is the variance in response times, and $\\beta$ balances the two factors. The use of temporal behavioral evidence is supported by results from large-scale distributed infrastructures, where historic performance traces have proven to be strong predictors of future reliability and availability patterns. This aligns with previous findings showing that temporal variability is not ran-dom but exhibits measurable structure suitable for predictive modeling [54] .",
                "description": null,
                "id": 84,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            433,
                            500,
                            468
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Composite reputation score. The final reputation score combines all dimensions using adaptive weighting:",
                "description": null,
                "id": 85,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            229,
                            480,
                            500,
                            533
                        ],
                        "page_id": 5
                    }
                ],
                "content": "R _ { i } ^ { t } = \\sum _ { j = 1 } ^ { 3 } w _ { j } ^ { t } \\cdot r _ { i , j } ^ { t } \\tag{5}",
                "description": null,
                "id": 86,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            547,
                            500,
                            580
                        ],
                        "page_id": 5
                    }
                ],
                "content": "where weights $w_j$ are dynamically adjusted based on the detected attack patterns and model convergence state.",
                "description": null,
                "id": 87,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            586,
                            500,
                            1080
                        ],
                        "page_id": 5
                    }
                ],
                "content": "The dynamic weighting mechanism (see Algorithm 1) is crucial to maintain robustness against evolving attack strate-gies. Rather than using fixed weights that attackers could learn and exploit, our framework dynamically assesses the discriminative power of each reputation dimension in every round. Our logic for assessing this power (lines 1-7) is based on two principles: (1) Variance (var<sub>f</sub>): A dimension is useful if it assigns a wide range of scores, as this indicates it is actively differentiating between clients. (2) Separation (sep<sub>f</sub>): A dimension is useful if it clearly separates the scores of historically “trusted” clients from historically “suspicious” clients. A dimension that scores high on both variance and separation is deemed a powerful and reliable discriminator for the current round, and its initial importance (n<sub>f</sub>) is amplified. This base importance is then adjusted based on the model's convergence state (Lines 8-13). This heuristic is designed to align the security posture with the training phase. For instance, during early training, legitimate clients exhibit high update variance as they explore the loss landscape. We therefore emphasize statistical anomaly detection (n<sub>t</sub>) to catch clear outliers, while slightly reducing the penalty for inconsistency (n<sub>t</sub>) to avoid flagging benign clients. Conversely, during late-stage convergence, legitimate updates should be highly consis-tent. We therefore emphasize the importance of the consistency score (n<sub>t</sub>) for detecting subtle deviations.",
                "description": null,
                "id": 88,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            1084,
                            500,
                            1120
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Third, the algorithm incorporates attack pattern recognition (Lines 14-24) by analyzing historical detection patterns. For",
                "description": null,
                "id": 89,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1140,
                            500,
                            1167
                        ],
                        "page_id": 5
                    }
                ],
                "content": "4The convergence-based weight multipliers were determined through comprehensive empirical analysis and theoretical considerations:",
                "description": null,
                "id": 90,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1168,
                            500,
                            1246
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Late training multipliers (1.5, 1.2): When conv* > conv., the model has largely converged. The 1.5× boost to consistency (r1) reflects that legitimate updates should be highly consistent at this stage. Our experiments showed that 95% of benign updates had cosine similarity >0.85 after convergence. The value 1.2× boost to temporal behavior (r3) helps detect intermittent attackers who become active during critical convergence phases.",
                "description": null,
                "id": 91,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            97,
                            937,
                            271
                        ],
                        "page_id": 5
                    }
                ],
                "content": "instance, if gradient scaling attacks are prevalent, the statistical\nanomaly dimension receives increased weight. This pattern-\naware adjustment enables the system to automatically tailor\nits detection strategy to observed threats. Finally, weights are\nnormalized using softmax to ensure they sum to one, and\ntemporal smoothing (Lines 24-27) prevents abrupt changes\nthat adversaries could exploit. This adaptive mechanism en-\nsures that FLARE maintains effectiveness against diverse and\nevolving attack strategies without manual reconfiguration.",
                "description": null,
                "id": 92,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            302,
                            806,
                            318
                        ],
                        "page_id": 5
                    }
                ],
                "content": "C. Dynamic Client Reliability Assessment",
                "description": null,
                "id": 93,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            329,
                            937,
                            383
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Our framework employs an adaptive threshold mechanism that adjusts reliability criteria based on the global model's state and historical attack patterns.",
                "description": null,
                "id": 94,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            386,
                            937,
                            443
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Adaptive threshold calculation. The reliability threshold $\\Theta^t$ at round $t$ evolves based on model convergence and detected anomalies:",
                "description": null,
                "id": 95,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            568,
                            455,
                            937,
                            476
                        ],
                        "page_id": 5
                    }
                ],
                "content": "\\Theta ^ { t } = \\Theta _ { b a s e } + \\gamma \\cdot \\mathrm { c o n v } ( u ^ { t } ) - \\delta \\cdot \\mathrm { a n o m a l y } _ { \\mathrm { r a t e } } ^ { t } \\tag{6}",
                "description": null,
                "id": 96,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            491,
                            937,
                            567
                        ],
                        "page_id": 5
                    }
                ],
                "content": "where $\\Theta_{base}$ is the baseline threshold, conv$(w^t)$ measures\nmodel convergence (higher values indicate stable training), and\nanomaly_rate$t$ represents the fraction of suspicious updates\ndetected in recent rounds.",
                "description": null,
                "id": 97,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            570,
                            937,
                            626
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Reputation decay and recovery. To handle dynamic client behaviors, we implement a reputation update mechanism with asymmetric decay and recovery rates:",
                "description": null,
                "id": 98,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            534,
                            639,
                            937,
                            684
                        ],
                        "page_id": 5
                    }
                ],
                "content": "R _ { i } ^ { t + 1 } = \\left\\{ \\begin{array} { l l } { \\mathrm { m i n } ( R _ { i } ^ { t } + \\rho _ { u p } , 1 ) } & { \\mathrm { i f ~ b e n i g n ~ b e h a v i o r } } \\\\ { \\mathrm { m a x } ( R _ { i } ^ { t } - \\rho _ { d o w n } , 0 ) } & { \\mathrm { i f ~ s u s p i c i o u s ~ b e h a v i o r } } \\\\ \\end{array} \\right. \\tag{7}",
                "description": null,
                "id": 99,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            700,
                            937,
                            754
                        ],
                        "page_id": 5
                    }
                ],
                "content": "where $\\rho_{up} < \\rho_{down}$ ensures that reputation is harder to\nbuild than to lose, preventing malicious clients from quickly\nrecovering after attacks.",
                "description": null,
                "id": 100,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            759,
                            937,
                            793
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Client classification. Based on reputation scores and adap-\ntive thresholds, clients are classified into three categories:",
                "description": null,
                "id": 101,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            534,
                            803,
                            937,
                            819
                        ],
                        "page_id": 5
                    }
                ],
                "content": "• Trusted (R<sub>i</sub> ≥ θ): Full participation with weight w<sub>i</sub> = 1",
                "description": null,
                "id": 102,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            824,
                            937,
                            859
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Suspicious ( $\\Theta^t / 2 \\leq R_i^t < \\Theta^t$ ): Limited participation\nwith weight $w_i = R_i^t / \\Theta^t$",
                "description": null,
                "id": 103,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            534,
                            863,
                            912,
                            878
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Untrusted (R<sub>i</sub><sup>b</sup> < θ<sup>b</sup>/2): Excluded from aggregation",
                "description": null,
                "id": 104,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            909,
                            771,
                            925
                        ],
                        "page_id": 5
                    }
                ],
                "content": "D. Reputation-Weighted Aggregation",
                "description": null,
                "id": 105,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            937,
                            937,
                            1011
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Instead of binary inclusion/exclusion (as shown in the Fig-\nures 1 and 3), we propose a reputation-weighted aggregation\nscheme that proportionally incorporates client contributions\nbased on their trustworthiness.",
                "description": null,
                "id": 106,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1015,
                            937,
                            1049
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Weighted FedAvg. The global model update incorporates reputation scores as weights:",
                "description": null,
                "id": 107,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            610,
                            1061,
                            937,
                            1106
                        ],
                        "page_id": 5
                    }
                ],
                "content": "w ^ { t } = w ^ { t - 1 } + \\frac { \\sum _ { i \\in \\mathcal { C } _ { t } } R _ { i } ^ { t } \\cdot n _ { i } \\cdot \\frac { \\triangle w _ { i } ^ { t } } { \\sum _ { i \\in \\mathcal { C } _ { t } } R _ { i } ^ { t } \\cdot n _ { i } } } { } \\tag{8}",
                "description": null,
                "id": 108,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1128,
                            937,
                            1207
                        ],
                        "page_id": 5
                    }
                ],
                "content": "Early training multipliers (1.3, 0.8): During initial rounds, legitimate clients naturally exhibit high variance. The 1.3× boost to anomaly detection (η2) helps identify statistical outliers that deviate beyond expected exploration patterns. The 0.8× reduction for consistency prevents flagging legitimate clients exploring the loss landscape. Our analysis found that benign update variance is 2.3× higher in early rounds compared to post-convergence.",
                "description": null,
                "id": 109,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1208,
                            937,
                            1246
                        ],
                        "page_id": 5
                    }
                ],
                "content": "These values were validated across 20 training rounds on MNIST, CIFAR-10, and SVHN datasets with various attack configurations, achieving optimal F1-scores of 0.92±0.03 for malicious client detection.",
                "description": null,
                "id": 110,
                "type": "footnote"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            41,
                            937,
                            53
                        ],
                        "page_id": 6
                    }
                ],
                "content": "7",
                "description": null,
                "id": 111,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            97,
                            494,
                            248
                        ],
                        "page_id": 6
                    }
                ],
                "content": null,
                "description": "A line graph plots multiple colored lines representing client scores over 200 communication rounds, accompanied by labeled horizontal bands.",
                "id": 112,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            258,
                            500,
                            392
                        ],
                        "page_id": 6
                    }
                ],
                "content": "Fig. 3: Reputation dynamics across training rounds for representative clients.\nThe curves illustrate per-round scores (performance consistency $r_{t1}$ , statistical anomaly $r_{2}$ , temporal behavior $r_{3}$ ), the combined reputation $R_{t}$ , the adaptive threshold $\\tau_{t}$ , and the resulting soft-exclusion weight $w_{t}$ . Benign clients maintain high $R_{t}$ and stable $w_{t}$ , while noisy-but-benign clients experience dips and recover. In contrast, malicious and adaptive clients exhibit sharp drops, followed by a decay in reputation, which prevents rapid trust recovery.\nThis explains how evidence over time is converted into aggregation weights and admission decisions.",
                "description": null,
                "id": 113,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            407,
                            500,
                            466
                        ],
                        "page_id": 6
                    }
                ],
                "content": "where $n_i$ is the number of samples at client $i$ . This soft weighting maintains model diversity while minimizing ma-licious influence.",
                "description": null,
                "id": 114,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            468,
                            500,
                            526
                        ],
                        "page_id": 6
                    }
                ],
                "content": "Normalization and clipping. To prevent reputation manipulation through gradient scaling attacks, we apply gradient clipping before aggregation:",
                "description": null,
                "id": 115,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            175,
                            541,
                            500,
                            588
                        ],
                        "page_id": 6
                    }
                ],
                "content": "\\Delta \\hat{w}_i^t = \\Delta w_i^t \\cdot \\mathrm{min} \\left( 1, \\frac{C}{\\| \\Delta w_i^t \\|_2 } \\right) \\tag{9}",
                "description": null,
                "id": 116,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            585,
                            500,
                            622
                        ],
                        "page_id": 6
                    }
                ],
                "content": "where $C$ is the clipping threshold determined by the median norm of updates.",
                "description": null,
                "id": 117,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            625,
                            500,
                            822
                        ],
                        "page_id": 6
                    }
                ],
                "content": "Differentially Private Reputation Assessment. The system model described in Section III-A assumes an \"honest-but-curious\" server, which, by calculating reputation scores Section III-B, has access to the clients' model updates, $\\Delta w_i^t$ .\nThis creates a potential privacy risk, as these updates could be reverse-engineered to infer information about a client's private data. To mitigate this risk, we integrate Local Differential Privacy (LDP) [55] , a strong privacy model that ensures client updates are anonymized before leaving the client device. The process is as follows:",
                "description": null,
                "id": 118,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            825,
                            500,
                            905
                        ],
                        "page_id": 6
                    }
                ],
                "content": "1) Client-Side Clipping: As defined in Eq. (9), each client\n$c_i$ first computes its clipped update $\\Delta \\tilde{w}^t_i$ . This step is critical\nas it bounds the $L_2$ -sensitivity of the update to the clipping\nthreshold $C$ .",
                "description": null,
                "id": 119,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            906,
                            500,
                            965
                        ],
                        "page_id": 6
                    }
                ],
                "content": "2) Client-Side Noise Addition: Before transmitting to the server, the client adds calibrated noise to the clipped update to satisfy $(\\epsilon,\\delta)$ -LDP [56] . We use the Gaussian mechanism:",
                "description": null,
                "id": 120,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            175,
                            974,
                            500,
                            1006
                        ],
                        "page_id": 6
                    }
                ],
                "content": "\\Delta w _ { i } ^ { t } { } _ { \\mathrm { p r i v a t e } } = \\Delta w _ { i } ^ { t } + \\mathcal{N } ( 0 , C ^ { 2 } \\sigma \\mathrm { T } ) \\tag{10}",
                "description": null,
                "id": 121,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1008,
                            500,
                            1065
                        ],
                        "page_id": 6
                    }
                ],
                "content": "where $\\sigma$ is the noise multiplier required to achieve the desired privacy budget $(\\epsilon,\\delta)$ for a sensitivity of $C$ , and $\\mathbf{I}$ is the identity matrix.",
                "description": null,
                "id": 122,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1068,
                            500,
                            1127
                        ],
                        "page_id": 6
                    }
                ],
                "content": "3) Server-Side Assessment on Private Data: The server receives only the set of private, noisy updates,\n$\\{\\Delta w_i^{',private}\\}_{i\\in C_t}$ .",
                "description": null,
                "id": 123,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1130,
                            500,
                            1246
                        ],
                        "page_id": 6
                    }
                ],
                "content": "The server performs the entire multi-dimensional reputation assessment Section III-B and dynamic thresholding III-C on these noisy updates. This introduces a clear privacy-utility trade-off: the server's scoring mechanism must now distin-\nguish between malicious deviations and statistically valid noise introduced for privacy. Our adaptive threshold mechanism",
                "description": null,
                "id": 124,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            90,
                            937,
                            776
                        ],
                        "page_id": 6
                    }
                ],
                "content": "<table><tr><th>Algorithm 2: FLARE Framework</th></tr><tr><td>Input: Number of rounds T, clients C, initial model w<sup>0</sup>, hyperparameters</td></tr><tr><td>$\\alpha, \\beta, \\gamma, \\delta, \\rho_{up}, \\rho_{down}$</td></tr><tr><td>Output: Final global model $u_T$</td></tr><tr><td>Initialization: $R_0^0 = 0.5 \\cdot \\gamma_i \\in \\mathbb{C}$; $\\Theta_0 = \\Theta_{base}$</td></tr><tr><td>for round $t = 1$ to $T$ do</td></tr><tr><td>1</td><td>// client selects to do</td></tr><tr><td>2</td><td>Select subset $C_t \\subset C$ based on $R_{t-1}^t$</td></tr><tr><td>3</td><td>Broadcast $C_t$ to all $i \\in C$</td></tr><tr><td>4</td><td>for each client $i \\in C_t$ do in parallel</td></tr><tr><td>5</td><td>$w_t^i \\leftarrow LOCALTRAINING(w_{t-1}^i, D_i)$</td></tr><tr><td>6</td><td>$\\Delta w_t^i \\leftarrow w_t^i - w_{t-1}^i - \\alpha \\Delta w_{t-1}^i$</td></tr><tr><td>7</td><td>Send $\\Delta w_t^i$ to server</td></tr><tr><td>8</td><td>// multi-dimensional reputation assessment</td></tr><tr><td>9</td><td>for each client $i \\in C_t$ do</td></tr><tr><td>10</td><td>$r_{t+1}^i \\leftarrow \\alpha r_{t-1}^i + (1 - \\alpha) \\cos(\\Delta w_t^i, \\Delta w_{t-1}^i)$</td></tr><tr><td>11</td><td>$d_t^i \\leftarrow MHALANOBIS(\\Delta w_t, (\\Delta w_{t-1}, \\Delta w_{t-1}^i))$</td></tr><tr><td>12</td><td>$r_{t+2}^i \\leftarrow ANOMALYSCORE(d_t, r_i, \\alpha)$</td></tr><tr><td>13</td><td>$r_{t+3}^i \\leftarrow \\beta p_t + (1 - \\beta) [1/(1 + \\sigma_{RT,i})] r_{t+1}^i$</td></tr><tr><td>14</td><td>// dynamic threshold adjustment</td></tr><tr><td>15</td><td>if $t = 1$ then</td></tr><tr><td>16</td><td>conv<sup>t</sup> $\\leftarrow 0$</td></tr><tr><td>17</td><td>else</td></tr><tr><td>18</td><td>conv<sup>t</sup> $\\leftarrow$ CONVERGENCE(w<sup>t-1</sup>, w<sup>t-2</sup>)</td></tr><tr><td>19</td><td>anomaly<sup>t</sup> $\\leftarrow \\{ i : R_t^i < \\Theta_{t-1}^i / 2 \\} / |C|$</td></tr><tr><td>20</td><td>$\\Theta_t^* \\leftarrow \\Theta_{base} + conv^t \\cdot \\delta$ anomaly<sup>t</sup></td></tr><tr><td>21</td><td>// Gradient clipping</td></tr><tr><td>22</td><td>$C \\leftarrow median(|\\Delta w_t^i| / 2) \\cdot \\epsilon_{c}$</td></tr><tr><td>23</td><td>for each client $i \\in C_t$ do</td></tr><tr><td>24</td><td>$\\Delta w_t^i \\leftarrow \\Delta w_t^* - \\min(1, C / | \\Delta w_t^i |)$</td></tr><tr><td>25</td><td>// Reputation-weighted aggregation</td></tr><tr><td>26</td><td>$C_{trusted}^t \\leftarrow \\{ i : R_t^i > \\Theta_{t-1}^i\\}$</td></tr><tr><td>27</td><td>$\\sum_{i \\in C_{trusted}} R_t^i n_i \\Delta w_t^i$</td></tr><tr><td>28</td><td>$w_t^* \\leftarrow w_t + \\frac{\\sum_{i \\in C_{trusted}} R_t^i n_i \\Delta w_t^i}{\\sum_{i \\in C_{trusted}} R_t^i n_i}$</td></tr><tr><td>29</td><td>// Reputation update for next round</td></tr><tr><td>30</td><td>for each client $i \\in C_t$ do</td></tr><tr><td>31</td><td>if $R_{t+1}^i \\geq \\Theta_{t-1}^i / 2$ then</td></tr><tr><td>32</td><td>$R_{t+1}^i \\leftarrow \\min(R_t^i + \\rho_{up}, 1)$</td></tr><tr><td>33</td><td>else</td></tr><tr><td>34</td><td>$R_{t+1}^i \\leftarrow \\max(R_t^i - \\rho_{down}, 0)$</td></tr><tr><td>35</td><td>return $w_T$</td></tr></table>",
                "description": null,
                "id": 125,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            797,
                            937,
                            853
                        ],
                        "page_id": 6
                    }
                ],
                "content": "(Eq. 6)) and multi-dimensional scoring are designed to tolerate this baseline level of noise while still identifying significant statistical outliers indicative of an attack.",
                "description": null,
                "id": 126,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            856,
                            937,
                            893
                        ],
                        "page_id": 6
                    }
                ],
                "content": "The final reputation-weighted aggregation (Eq. (8)) is then\nalso computed using these same private updates:",
                "description": null,
                "id": 127,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            590,
                            903,
                            937,
                            959
                        ],
                        "page_id": 6
                    }
                ],
                "content": "w^{t+1} = w^{t} + \\eta \\frac{\\sum_{i \\in C^{t}_{trusted}} R_{i}^{t} n_{i} \\Delta w_{i,private}}{\\sum_{i \\in C^{t}_{trusted}} R_{i}^{t} n_{i}}",
                "description": null,
                "id": 128,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            962,
                            937,
                            999
                        ],
                        "page_id": 6
                    }
                ],
                "content": "where $R_t^t$ is the reputation score computed from the noisy data.",
                "description": null,
                "id": 129,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1027,
                            804,
                            1043
                        ],
                        "page_id": 6
                    }
                ],
                "content": "E. Algorithm Details and Implementation",
                "description": null,
                "id": 130,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1050,
                            937,
                            1148
                        ],
                        "page_id": 6
                    }
                ],
                "content": "Algorithm 2 presents the complete FLARE framework,\nwhich orchestrates dynamic client reliability assessment\nthrough reputation-based federated learning. We now provide\na detailed explanation of each component and its role in\nachieving robust model training.",
                "description": null,
                "id": 131,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1151,
                            937,
                            1246
                        ],
                        "page_id": 6
                    }
                ],
                "content": "Initialization phase. The algorithm begins by initializing all client reputation scores to $R_t^t=0=0.5$ representing a neutral starting point that neither trusts nor distrusts new clients. This balanced initialization prevents the system from being overly permissive or restrictive during early training rounds. The",
                "description": null,
                "id": 132,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            931,
                            41,
                            938,
                            53
                        ],
                        "page_id": 7
                    }
                ],
                "content": "S",
                "description": null,
                "id": 133,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            93,
                            500,
                            131
                        ],
                        "page_id": 7
                    }
                ],
                "content": "threshold $\\Theta^{t=0}$ is set to $\\Theta_{base}$ which serves as the baseline reliability criterion before adaptive adjustments begin.",
                "description": null,
                "id": 134,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            136,
                            500,
                            351
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Client selection and participation (Lines 1-7). At each\nround $t$ , the server strategically selects a subset $C_t$ of clients\nbased on their reputation scores from the previous round.\nClients with higher reputation scores are more likely to be\nselected, naturally filtering out consistently unreliable partici-\npants while maintaining diversity. The selected clients receive\nthe current global model, $w^{t-1}$ , and perform local training\non their private datasets, $D_i$ . Each client computes its model\nupdate $\\Delta w_i^t$ as the difference between its locally trained model\nand the received global model, and transmits it back to the\nserver.",
                "description": null,
                "id": 135,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            355,
                            500,
                            413
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Multi-dimensional reputation assessment (Lines 8-13).\nThe core innovation lies in the comprehensive reputation evaluation that captures multiple behavioral aspects:",
                "description": null,
                "id": 136,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            421,
                            500,
                            580
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Performance consistency ( $r_{t,1}^t$ , Line 9): This score\nmeasures the directional consistency of a client's updates\nover time. By computing the cosine similarity between the\ncurrent update $\\Delta w_t^t$ and the exponential moving average of\npast updates $\\Delta w_i^{t-1}$ , we detect sudden behavioral changes\nthat may indicate compromise. The decay factor $\\alpha$ controls\nthe influence of historical behavior, with higher values giving\nmore weight to past patterns.",
                "description": null,
                "id": 137,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            582,
                            500,
                            760
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Statistical anomaly detection ( $r_{i,2}$ , Lines 10-11): The\nMahalanobis distance $d_i^t$ quantifies how statistically unusual\na client's update is relative to the distribution of all updates\nin the current round. This metric accounts for parameter\ncorrelations, providing more accurate outlier detection than\nthe simple Euclidean distance. The anomaly score function\nconverts this distance into a reputation component, severely\npenalizing updates that deviate significantly from the norm\nwhile tolerating minor variations.",
                "description": null,
                "id": 138,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            762,
                            500,
                            899
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Temporal behavior analysis ( $r_{i,t}^t$ , Line 12): This component evaluates participation patterns and response time consistency. The participation rate $p_i^t$ captures how regularly a client contributes to training, while the response time variance $\\sigma_{RT,i}$ identifies clients with erratic behavior. The parameter $\\beta$ balances these two factors, enabling the detection of free riders and intermittently malicious clients.",
                "description": null,
                "id": 139,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            906,
                            500,
                            986
                        ],
                        "page_id": 7
                    }
                ],
                "content": "The composite reputation score $R_t$ (Line 13) combines these three dimensions using adaptive weights $w_t^f$ that can be adjusted based on the predominant attack types observed in the system.",
                "description": null,
                "id": 140,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            989,
                            500,
                            1226
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Dynamic threshold adjustment (Lines 14-19). The adaptive threshold mechanism represents a crucial departure from static defense methods. The convergence metric conv$^\\dagger$ measures how much the global model is changing between rounds. High convergence indicates stable training, where stricter qual-ity control is beneficial. The anomaly rate anomaly$^\\dagger$ quantifies the fraction of suspicious clients detected in the current round. The threshold $\\Theta$† increases when the model is converging (requiring higher-quality updates) and decreases when many anomalies are detected (to avoid overfiltering during attacks) as the model converges (requiring higher-quality updates to im-prove its security posture in response to current conditions.",
                "description": null,
                "id": 141,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            98,
                            1230,
                            500,
                            1246
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Gradient clipping (Lines 20-22). Before aggregation, all",
                "description": null,
                "id": 142,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            97,
                            938,
                            230
                        ],
                        "page_id": 7
                    }
                ],
                "content": "updates undergo gradient clipping to prevent manipulation through gradient scaling attacks. The clipping threshold $C$ is set to the median norm of all updates, ensuring that no single client can dominate the aggregation by using artificially large gradients. This median-based approach is robust to outliers, maintaining effectiveness even when multiple malicious clients coordinate their attacks.",
                "description": null,
                "id": 143,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            234,
                            938,
                            451
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Reputation-weighted aggregation (Lines 23-24). The\naggregation step fundamentally differs from traditional ap-\nproaches by incorporating reputation scores as weights. Only\nclients in the trusted set $C^t$ (those with $R_i^t \\geq \\Theta^t /2$ ) con-\ntribute to the global model update. Within this set, each client's\ncontribution is further weighted by their reputation score, $R_i^t$ ,\nand dataset size, $n_i$ . This soft weighting mechanism achieves\ntwo critical goals: (i) it prevents the complete exclusion of\npartially reliable clients who may have valuable data, and (ii) it\nminimizes the influence of suspicious clients without requiring\nperfect detection.",
                "description": null,
                "id": 144,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            455,
                            938,
                            691
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Reputation evolution (Lines 25-30). The reputation update mechanism implements asymmetric adjustment rates to reflect the principle that trust is hard to build but easy to lose. Clients demonstrating reliable behavior (those above the threshold) receive a small reputation increase, $\\rho_{up}$ , which gradually builds trust through consistent performance. Conversely, clients ex-hibiting suspicious behavior face a larger reputation penalty $\\rho_{down}$ , with $\\rho_{down} > \\rho_{up}$ ensuring rapid isolation of threats. This asymmetry prevents malicious clients from gaming the system by alternating between good and bad behavior, as the reputation loss from attacks exceeds the potential gains from benign rounds.",
                "description": null,
                "id": 145,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            694,
                            938,
                            850
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Computational complexity. The algorithm's computational complexity is $O(|C_t| \\cdot d)$ per round, where $d$ is the model dimension. The reputation scoring adds minimal overhead compared to standard FL aggregation, as the most expensive operation can be efficiently implemented using incremental covariance updates. The memory requirements are $O(N)$ for storing reputation scores and $O(d^2)$ for the covariance matrix, both of which are manageable for typical FL deployments.",
                "description": null,
                "id": 146,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            854,
                            938,
                            1009
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Privacy considerations. Importantly, the algorithm pre-serves client privacy as the server only observes model updates, not raw data. The reputation scores themselves are computed solely from these updates and timing information, without requiring additional client information. The privacy-preserving reputation proofs (mentioned in Section III-D) are integrated, allowing clients to prove their reputation standing without revealing exact scores.",
                "description": null,
                "id": 147,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1015,
                            938,
                            1092
                        ],
                        "page_id": 7
                    }
                ],
                "content": "Algorithm summary. Algorithm [2] presents the complete FLARE framework, integrating reputation scoring, dynamic assessment, and weighted aggregation into a cohesive system for robust federated learning.",
                "description": null,
                "id": 148,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            610,
                            1123,
                            847,
                            1137
                        ],
                        "page_id": 7
                    }
                ],
                "content": "IV. PERFORMANCE EVALUATION",
                "description": null,
                "id": 149,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1151,
                            938,
                            1246
                        ],
                        "page_id": 7
                    }
                ],
                "content": "We conduct comprehensive experiments to evaluate the ef-\nfectiveness of FLARE across various attack scenarios and com-\npare its performance with that of state-of-the-art Byzantine-\nrobust methods. Our evaluation focuses on robustness, con-\nvergence speed, and computational overhead.",
                "description": null,
                "id": 150,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            47,
                            937,
                            63
                        ],
                        "page_id": 8
                    }
                ],
                "content": "",
                "description": null,
                "id": 151,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            142,
                            88,
                            438,
                            102
                        ],
                        "page_id": 8
                    }
                ],
                "content": "TABLE III: Experimental Environment Configuration",
                "description": null,
                "id": 152,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            103,
                            494,
                            337
                        ],
                        "page_id": 8
                    }
                ],
                "content": "<table><tr><th>Component</th><th>Specification</th><th></th><th></th></tr><tr><td colspan=\"4\">Hardware Configuration</td></tr><tr><td>CPU</td><td>Intel Xeon Gold 6248R (24 cores @ 3.0GHz)</td><td></td><td></td></tr><tr><td>GPU</td><td>4 x NVIDIA RTX 2070 (8GB each)</td><td></td><td></td></tr><tr><td>RAM</td><td>256GB DDR4 ECC</td><td></td><td></td></tr><tr><td>Storage</td><td>2TB NVMe SSD</td><td></td><td></td></tr><tr><td colspan=\"4\">Software Configuration</td></tr><tr><td>Operating System</td><td>Ubuntu 24.04 LTS</td><td></td><td></td></tr><tr><td>Python</td><td>3.13</td><td></td><td></td></tr><tr><td>PyTorch</td><td>2.6 with CUDA 12.6</td><td></td><td></td></tr><tr><td colspan=\"4\">TABLE IV: Dataset Characteristics and Model Architectures</td></tr><tr><th>Dataset</th><th>Classes</th><th>Train/Test</th><th>Model</th><th>Parameters</th></tr><tr><td>MNIST</td><td>10</td><td>60K/10K</td><td>2-layer CNN</td><td>431K</td></tr><tr><td>CIFAR-10</td><td>10</td><td>50K/10K</td><td>ResNet-18</td><td>11.2M</td></tr><tr><td>SVHN</td><td>10</td><td>73K/26K</td><td>5-layer CNN</td><td>1.8M</td></tr></table>",
                "description": null,
                "id": 153,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            357,
                            236,
                            371
                        ],
                        "page_id": 8
                    }
                ],
                "content": "A. Experimental Setup",
                "description": null,
                "id": 154,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            380,
                            500,
                            597
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Implementation environment. All experiments are conducted on the hardware and software configuration detailed in Table III. We use a distributed setup with a central server and 100 clients (see Fig. 4) to replicate realistic federated learning scenarios. The server manages aggregation and reputation scoring, while client computations are parallelized using multiprocessing to simulate concurrent local training. Client selection in each round follows a uniform random distribution among eligible clients (those meeting reputation thresholds for methods that employ them). Each experimental configuration is repeated five times to ensure statistical significance.",
                "description": null,
                "id": 155,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            598,
                            500,
                            716
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Datasets and models. Table IV summarizes the datasets and model architectures used in our evaluation. We consider both IID and non-IID data settings. For the non-IID case, we apply Dirichlet partitioning with concentration parameters $\\alpha \\in \\{0.7, 0.5, 0.3, 0.1\\}$ to simulate different levels of data heterogeneity [5], [57], [58] .",
                "description": null,
                "id": 156,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            719,
                            500,
                            854
                        ],
                        "page_id": 8
                    }
                ],
                "content": "For the MNIST dataset [59] , we employ a lightweight 2-layer CNN with two convolutional layers (32 and 64 filters), max pooling, and two fully connected layers. The CIFAR-10 [60] experiments utilize a standard ResNet-18 architecture adapted for 32 $\\times$ 32 images. For SVHN [61] , we design a 5-layer CNN with batch normalization and dropout (0.3) to handle the increased complexity of street view images.",
                "description": null,
                "id": 157,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            856,
                            500,
                            934
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Attack configurations. Table $\\square$ details the four attack types implemented in our experiments [48], [49], [62]. Each attack is carefully calibrated to represent realistic threat scenarios, al-lowing for the systematic evaluation of defense effectiveness.",
                "description": null,
                "id": 158,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            950,
                            500,
                            994
                        ],
                        "page_id": 8
                    }
                ],
                "content": "5 Malicious clients are selected using a random uniform distribution, where\neach client has equal probability $P(c_i \\in \\mathcal{M}) = f/N$ of being compromised,\nwith $f$ being the number of attackers and $N$ the total number of clients.",
                "description": null,
                "id": 159,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            129,
                            1014,
                            454,
                            1161
                        ],
                        "page_id": 8
                    }
                ],
                "content": null,
                "description": "A box plot compares the distribution of \"Malicious Clients,\" \"Benign Clients,\" and \"Clients with certain Attack\" across a range of values.",
                "id": 160,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1170,
                            500,
                            1242
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Fig. 4: Client Role Distribution for 100 Clients in a scenario where all 6\nattack types might occur. We expect to have around 80 benign clients (pink\nbox) and 20 malicious clients (green box), where each malicious client is\nassigned with one of 6 attack behaviors, meaning we expect (≈ 3) malicious\nclients for each attack pattern (orange box)",
                "description": null,
                "id": 161,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            97,
                            937,
                            190
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Coluding adversaries estimate the statistical pro-\nfile of honest gradients and subtly bias updates in the direction\nof maximal model degradation. The attack evades simple\noutlier filtering because it aligns with the expected gradient\nvariance.",
                "description": null,
                "id": 162,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            196,
                            937,
                            292
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Statistical Mimicry (SM). Adversaries continuously learn the global gradient distribution and inject blended updates that remain statistically consistent while biasing convergence. This attack challenges defenses that rely purely on per-round statistical deviations.",
                "description": null,
                "id": 163,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            299,
                            937,
                            435
                        ],
                        "page_id": 8
                    }
                ],
                "content": "The label flipping attack represents data poisoning, where\nmalicious clients train on incorrectly labeled data [48], [49],\n[62] . Byzantine gradient attacks simulate complete client\ncompromise by sending random noise [48] . Gradient scaling\nattacks aim to dominate aggregation by amplifying updates\n[49], [62] . Adaptive attacks model sophisticated adversaries\nthat evade detection by intermittently behaving normally [48]",
                "description": null,
                "id": 164,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            440,
                            937,
                            614
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Baselines. We compare FLARE against seven baseline methods: FedAvg [5]: Standard aggregation without defense, Krum [21]: Byzantine-robust aggregation selecting closest updates, Trimmed Mean [19]: Coordinate-wise trimmed av- eraging, FLTrust [63]: Trust bootstrapping with server val- idation data, FLAME [64]: Adaptive clipping and noise addition, BREA [65]: Byzantine-resilient secure aggregation framework, Repunet [27]: Reputation system for mitigating malicious clients in decentralized FL.",
                "description": null,
                "id": 165,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            620,
                            937,
                            697
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Hyperparameter configuration. Table VI presents the hyperparameters used in our experiments. These values were determined via a systematic grid search[6] on a validation set comprising 10% of the training data.",
                "description": null,
                "id": 166,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            701,
                            937,
                            778
                        ],
                        "page_id": 8
                    }
                ],
                "content": "Metrics. We evaluate performance using: (i) Test accuracy;\nModel performance on held-out test data, (ii) Robustness: Per-\ncentage of rounds where malicious clients successfully degrade\nmodel performance by >5%; (iii) Convergence speed: Rounds",
                "description": null,
                "id": 167,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            534,
                            806,
                            776,
                            821
                        ],
                        "page_id": 8
                    }
                ],
                "content": "See Section II-B of supplementary material",
                "description": null,
                "id": 168,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            591,
                            832,
                            866,
                            844
                        ],
                        "page_id": 8
                    }
                ],
                "content": "TABLE V: Attack Configurations and Parameters",
                "description": null,
                "id": 169,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            846,
                            937,
                            937
                        ],
                        "page_id": 8
                    }
                ],
                "content": "<table><thead><tr><td><b>Attack Type</b></td><td><b>Description</b></td><td><b>Parameters</b></td></tr></thead><tbody><tr><td>Label Flipping</td><td>Systematically corrupt labels</td><td>Target: (<i>p</i> + 1) mod 10</td></tr><tr><td>Byzantine Gradient</td><td>Send random noise as updates</td><td><i>σ</i><sup>2</sup> ∈ [0.1, 0.5, 1.0]</td></tr><tr><td>Gradient Scaling</td><td>Amplify gradient magnitude</td><td>λ ∈ [2, 5, 10]</td></tr><tr><td>Adaptive Attack</td><td>Alternate between benign and malicious updates</td><td>70% benign, 30% attack</td></tr><tr><td>ALJE<sup>[41]</sup></td><td>Creates a fully coherent malicious update by sampling from the estimated honest distribution (<i>g</i><sup><i>h</i></sup><sub><i>i</i></sub><sup><i>k</i></sup><sub><i>j</i></sub><sup><i>t</i></sup><sub><i>l</i></sub><sup><i>s</i></sup><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>f</i></sub><sub><i>g</i></sub><sub><i>h</i></sub><sub><i>i</i></sub><sub><i>j</i></sub><sub><i>k</i></sub><sub><i>l</i></sub><sub><i>m</i></sub><sub><i>n</i></sub><sub><i>o</i></sub><sub><i>p</i></sub><sub><i>q</i></sub><sub><i>r</i></sub><sub><i>s</i></sub><sub><i>t</i></sub><sub><i>u</i></sub><sub><i>v</i></sub><sub><i>w</i></sub><sub><i>x</i></sub><sub><i>y</i></sub><sub><i>z</i></sub><sub><i>a</i></sub><sub><i>b</i></sub><sub><i>c</i></sub><sub><i>d</i></sub><sub><i>e</i></sub><sub><i>",
                "description": null,
                "id": 170,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            591,
                            946,
                            866,
                            959
                        ],
                        "page_id": 8
                    }
                ],
                "content": "in a single round but accumulates over time",
                "description": null,
                "id": 171,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            961,
                            866,
                            1243
                        ],
                        "page_id": 8
                    }
                ],
                "content": "<table><tr><th>Parameter</th><th>Description</th><th>Value</th></tr><tr><td colspan=\"3\">Reputation Scoring Parameters</td></tr><tr><td>α</td><td>Consistency decay factor</td><td>0.7</td></tr><tr><td>β</td><td>Temporal behavior weight</td><td>0.7</td></tr><tr><td>τd</td><td>Anomaly threshold</td><td>2.5</td></tr><tr><td>λ</td><td>Penalty severity</td><td>0.5</td></tr><tr><td colspan=\"3\">Adaptive Threshold Parameters</td></tr><tr><td>γ</td><td>Convergence influence</td><td>0.4</td></tr><tr><td>δ</td><td>Anomaly rate influence</td><td>0.5</td></tr><tr><td>Θbase</td><td>Baseline threshold</td><td>0.5</td></tr><tr><td colspan=\"3\">Reputation Update Parameters</td></tr><tr><td>ρup</td><td>Reputation increase rate</td><td>0.05</td></tr><tr><td>ρdown</td><td>Reputation decrease rate</td><td>0.15</td></tr><tr><td colspan=\"3\">Training Parameters</td></tr><tr><td>T</td><td>Total rounds</td><td>200</td></tr><tr><td>|C1|</td><td>Clients per round</td><td>10</td></tr><tr><td>E</td><td>Local epochs</td><td>5</td></tr><tr><td>η</td><td>Learning rate</td><td>0.001</td></tr><tr><td>Batch size</td><td>Local training batch</td><td>32</td></tr><tr><td>Optimizer</td><td>Local optimization</td><td>ADAM</td></tr></table>",
                "description": null,
                "id": 172,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            47,
                            937,
                            63
                        ],
                        "page_id": 9
                    }
                ],
                "content": "112",
                "description": null,
                "id": 173,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            97,
                            500,
                            131
                        ],
                        "page_id": 9
                    }
                ],
                "content": "required to reach 90% of final accuracy, and (iv) Detection\nmetrics: Precision and recall for identifying malicious clients.",
                "description": null,
                "id": 174,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            152,
                            233,
                            168
                        ],
                        "page_id": 9
                    }
                ],
                "content": "B. Evaluation Results",
                "description": null,
                "id": 175,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            177,
                            500,
                            790
                        ],
                        "page_id": 9
                    }
                ],
                "content": "Table VII shows that the full FLARE configuration keeps high accuracy as the fraction of Byzantine clients grows on 85.1% to 10. Accuracy goes from 92.2% at 5% attackers to 21.8%. At 30% attackers. All ablated variants drop faster. The largest drops appear when we remove Soft Exclusion or Multi-dimensional Scoring. At 30% attackers, these versions fall to 76.7% and 77.6%. These results support two main reasons. First, multi-dimensional scoring combines perfor- mance consistency (r1), statistical anomaly (r2), and temporal behavior (r3). This helps distinguish between truly malicious behavior and normal non-IID variation. Second, soft exclusion turns scores into continuous weights. This limits the effect of suspicious clients while still keeping some signal from uncertain but benign clients. Adaptive Thresholds also help because they tighten participation as the model converges. Reputation Decay reduces the chance that a client can mis- behave, then act well briefly, and regain full trust. Together, these parts explain the flatter degradation curve of the full system. Table VIII ranks components by average accuracy loss when removed. Soft Exclusion and Multi-dimensional Scoring have the largest impact (8.38% and 7.61%). Adaptive Thresholds and the Statistical Anomaly test follow next. This ordering matches the behavior in Table VII. First, make a well-informed decision with multi-evidence scoring. Second, weight clients smoothly with soft exclusion. Third, adjust acceptance over time with adaptive thresholds. Reputation Decay and Performance Consistency still matter because they influence long-term behavior and mitigate the impact of clients who do not contribute across rounds. The small change when Privacy Preservation is removed suggests that privacy and robustness are not in conflict in this design.",
                "description": null,
                "id": 176,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            793,
                            500,
                            1246
                        ],
                        "page_id": 9
                    }
                ],
                "content": "Table IX reports detection quality after 200 rounds. F1-scores remain high across datasets and attacks. For example, on MNIST, the score is 0.958 with no attack and 0.916 under adaptive attack. On SVHN, the results are 0.895 and 0.889. On CIFAR-10, the results are 0.855 and 0.787. The mixed case with all attack patterns is the most challenging, especially on CIFAR-10 (0.681), but the performance remains useful. The reason is that we combine three views. The anomaly detector (r2) maintains precision by flagging outliers in gradients and metrics. The temporal view (r3) and Reputation Decay maintain recall against clients that change behavior over time. Performance Consistency (r1) reduces the influence of clients that repeatedly fail to support global progress. Table IX shows the weighted average loss after 200 rounds. Values remain close to the no-attack baseline across attacks and datasets. On CIFAR-10 the loss stays near 1.49 in all cases. On MNIST, it lies between 0.122 and 0.168. On SVHN, it lies around 0.456 to 0.511. These results indicate stable optimization. Reputation-weighted aggregation limits harmful updates and keeps useful diversity. Gradient Clipping reduces the effect of gradient scaling and noisy updates without stopping learning. Even the mixed attack case does not inflate the loss, which is consistent with effective suppression of harmful contributions.",
                "description": null,
                "id": 177,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            88,
                            937,
                            118
                        ],
                        "page_id": 9
                    }
                ],
                "content": "TABLE VII: Accuracy Degradation vs. Malicious Client Fraction (Byzantine\nAttack, CIFAR-10)",
                "description": null,
                "id": 178,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            118,
                            937,
                            292
                        ],
                        "page_id": 9
                    }
                ],
                "content": "<table><tr><th>Configuration</th><th>5%</th><th>10%</th><th>20%</th><th>30%</th></tr><tr><td>Full FLARE</td><td>92.2</td><td>90.6</td><td>88.6</td><td>85.1</td></tr><tr><td>w/o Performance Consistency (r<sub>1</sub>)</td><td>88.0</td><td>86.6</td><td>83.2</td><td>80.8</td></tr><tr><td>w/o Statistical Anomaly (r<sub>2</sub>)</td><td>86.9</td><td>85.2</td><td>82.6</td><td>79.4</td></tr><tr><td>w/o Temporal Behavior (r<sub>3</sub>)</td><td>89.9</td><td>88.1</td><td>85.0</td><td>82.4</td></tr><tr><td>w/o Adaptive Threshold</td><td>85.8</td><td>84.5</td><td>81.9</td><td>79.7</td></tr><tr><td>w/o Soft Exclusion</td><td>83.5</td><td>82.4</td><td>79.9</td><td>76.7</td></tr><tr><td>w/o Reputation Decay</td><td>87.9</td><td>85.9</td><td>83.6</td><td>80.0</td></tr><tr><td>w/o Privacy Preservation</td><td>90.4</td><td>88.6</td><td>85.9</td><td>83.3</td></tr><tr><td>w/o Gradient Clipping</td><td>88.5</td><td>86.6</td><td>84.0</td><td>81.1</td></tr><tr><td>w/o Multi-dimensional Scoring</td><td>85.8</td><td>83.0</td><td>80.6</td><td>77.6</td></tr></table>",
                "description": null,
                "id": 179,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            293,
                            937,
                            323
                        ],
                        "page_id": 9
                    }
                ],
                "content": "TABLE VIII: Component Importance Ranking by Average Performance Degradation",
                "description": null,
                "id": 180,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            323,
                            937,
                            468
                        ],
                        "page_id": 9
                    }
                ],
                "content": "<table><tr><th>Rank</th><th>Component</th><th>Avg. Degradation (%)</th><th>Std. Dev.</th></tr><tr><td>1</td><td>Soft Exclusion</td><td>8.38</td><td>0.51</td></tr><tr><td>2</td><td>Multi-dimensional Scoring</td><td>7.61</td><td>0.56</td></tr><tr><td>3</td><td>Adaptive Threshold</td><td>5.91</td><td>0.48</td></tr><tr><td>4</td><td>Statistical Anomaly (r2)</td><td>5.57</td><td>0.56</td></tr><tr><td>5</td><td>Reputation Decay</td><td>4.52</td><td>0.53</td></tr><tr><td>6</td><td>Performance Consistency (r1)</td><td>4.16</td><td>0.38</td></tr><tr><td>7</td><td>Gradient Clipping</td><td>3.91</td><td>0.64</td></tr><tr><td>8</td><td>Temporal Behavior (r3)</td><td>2.75</td><td>0.71</td></tr><tr><td>9</td><td>Privacy Preservation</td><td>1.77</td><td>0.2</td></tr></table>",
                "description": null,
                "id": 181,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            486,
                            937,
                            1118
                        ],
                        "page_id": 9
                    }
                ],
                "content": "Table IX represents small changes in total aggregation time across attack settings. On MNIST, the time is approximately 11 seconds. On SVHN, it takes about 21 to 24 seconds.\nOn CIFAR-10, it takes about 36 to 39 seconds. The main operations in our method are lightweight statistics, scoring, reweighting, and clipping. These add little overhead compared to standard aggregation. Thus the method improves robustness with little extra wall time. Table X studies accuracy at 20% malicious clients. The full system is best in every dataset and attack type. On CIFAR-10, it reaches 87.5% for label flip, 88.6% for Byzantine, 89.4% for gradient scaling, and 87.0% for adaptive attack. Removing Soft Exclusion or Multi-dimensional Scoring causes the largest drops, often 7 to 10 points. Removing Adaptive Thresholds hurts most in later training when the model is stable and low quality updates are more harmful. Turning off Reputation Decay hurts more under adaptive attacks, because clients can behave well briefly to regain trust. Turning off Gradient Clipping reduces accuracy mainly in the gradient scaling column. Removing Privacy Preservation changes accuracy only slightly, which again suggests that privacy support is compatible with robustness in this system. It is useful to group the components into three cooperating sets. First, front-end discrimination: Multi-dimensional Scoring together with Adaptive Thresholds pro- vides most of the separation between benign and malicious clients (Tables VIII and X). Second, aggregation control: Soft Exclusion and Gradient Clipping bound the impact of uncertain or adversarial updates while keeping potentially useful information (Tables VII and IX). Third, long-term resilience: Reputation Decay and Temporal Behavior protect against clients that change behavior across rounds and are hard to detect in a single round (Tables IX and X). These groups",
                "description": null,
                "id": 182,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            1128,
                            937,
                            1156
                        ],
                        "page_id": 9
                    }
                ],
                "content": "TABLE IX: Performance Comparison after 200 Rounds under $\\alpha=0.3$ : F1-\nscore, Weighted Average Loss, and Cumulated Aggregation Time (s)",
                "description": null,
                "id": 183,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1156,
                            937,
                            1246
                        ],
                        "page_id": 9
                    }
                ],
                "content": "<table><thead><tr><td rowspan=\"2\"><b>Attack Pattern</b></td><td colspan=\"3\"><b>FI-score</b></td><td colspan=\"3\"><b>Weighted Avg. Loss</b></td><td colspan=\"3\"><b>Aggregation Time (s)</b></td></tr><tr><td><b>MNIST</b></td><td><b>SVHN</b></td><td><b>CIFAR-10</b></td><td><b>MNIST</b></td><td><b>SVHN</b></td><td><b>CIFAR-10</b></td><td><b>MNIST</b></td><td><b>SVHN</b></td><td><b>CIFAR-10</b></td></tr></thead><tbody><tr><td>No Attack</td><td>0.955</td><td>0.895</td><td>0.855</td><td>0.142</td><td>0.464</td><td>1.493</td><td>11.11</td><td>22.00</td><td>37.2</td></tr><tr><td>Label Flipping</td><td>0.929</td><td>0.891</td><td>0.790</td><td>0.156</td><td>0.456</td><td>1.491</td><td>12.01</td><td>23.35</td><td>38.9</td></tr><tr><td>Byzantine Gradient</td><td>0.939</td><td>0.885</td><td>0.784</td><td>0.168</td><td>0.511</td><td>1.490</td><td>10.93</td><td>23.58</td><td>35.9</td></tr><tr><td>Gradient Scaling</td><td>0.928</td><td>0.886</td><td>0.771</td><td>0.141</td><td>0.490</td><td>1.502</td><td>11.10</td><td>20.98</td><td>38.2</td></tr><tr><td>Adaptive Attack</td><td>0.916</td><td>0.889</td><td>0.787</td><td>0.134</td><td>0.476</td><td>1.500</td><td>11.17</td><td>21.79</td><td>39.2</td></tr><tr><td>ALIE</td><td>0.863</td><td>0.226</td><td>0.293</td><td>0.287</td><td>1.156</td><td>3.847</td><td>12.45</td><td>24.12</td><td>40.3</td></tr><tr><td>SM Attack</td><td>0.826</td><td>0.511</td><td>0.71</td><td>0.143</td><td>1.285</td><td>1.596</td><td>11.86</td><td>22.67</td><td>38.7</td></tr><tr><td>All Attack Patterns</td><td>0.904</td><td>0.888</td><td>0.681</td><td>0.122</td><td>0.492</td><td>1.485</td><td>11.14</td><td>21.24</td><td>36.5</td></tr></tbody></table>",
                "description": null,
                "id": 184,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            927,
                            41,
                            938,
                            53
                        ],
                        "page_id": 10
                    }
                ],
                "content": "1-1",
                "description": null,
                "id": 185,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            97,
                            500,
                            466
                        ],
                        "page_id": 10
                    }
                ],
                "content": null,
                "description": "The image displays six bar charts, each comparing multiple methods (FedAvg, Trimmed Mean, etc.) across Precision, Recall, and F1 scores.",
                "id": 186,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            471,
                            500,
                            545
                        ],
                        "page_id": 10
                    }
                ],
                "content": "Fig. 5: Comparison of detection performance (Precision, Recall, and F1-\nScore) of eight FL methods across six attack scenarios on MNIST: Adaptive,\nByzantine Gradient, Gradient Scaling, Label Flip, ALIE, and SM Attack. Each\nsubplot reports the average detection quality along with confidence intervals.\nHigher values indicate better detection effectiveness.",
                "description": null,
                "id": 187,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            563,
                            500,
                            800
                        ],
                        "page_id": 10
                    }
                ],
                "content": "explain why the full system degrades slowly as the attacker\nfraction increases and why each individual ablation causes\nharm in a predictable manner. In summary, the full FLARE\nmodel is better for five linked reasons that are supported by\nthe tables. It has the best end accuracy under all attack types\n(Table IX). It degrades more slowly as the number of malicious\nclients grows (Table VII). It keeps strong detection quality,\nincluding under adaptive strategies (Table IX). It preserves\nstable optimization without increasing loss (Table IX). It adds\nlittle time overhead in training. Because these gains arise\nfrom components that address different failure modes and time\nscales, they are consistent across datasets and attacks.",
                "description": null,
                "id": 188,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            807,
                            500,
                            1024
                        ],
                        "page_id": 10
                    }
                ],
                "content": "Figure 5 compares FLARE with FedAvg, Krum, Trimmed Mean, FLTrust, FLAME, BREA, and Repunet using three detection metrics: precision, recall, and F1-Score. In every\nsubfigure, our method achieves the highest F1-score and\nmaintains both precision and recall at a high level. This means\nit accurately identifies malicious clients and minimizes both\nthe number of false alarms and the number of missed clients.\nAcross all six attack types, FLARE achieves improvements\nof roughly 15–30% in F1-score over the strongest baselines\nand often exceeds them by 10–25% in recall, indicating a\nconsistently stronger detection capability.",
                "description": null,
                "id": 189,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            81,
                            1031,
                            500,
                            1246
                        ],
                        "page_id": 10
                    }
                ],
                "content": "Normal Attacks. In the adaptive attack case (Figure 5a),\nthe gap is most important. Adaptive attackers change behavior\nover time to regain trust. Our method keeps a high recall\nbecause it uses temporal behavior (r3) and reputation decay\nto track clients across rounds. At the same time, precision\nstays high because statistical anomaly scoring (r2) reduces\nfalse positives from benign but unusual updates. Methods that\nrely mainly on geometric pruning, such as Krum and Trimmed\nMean, tend to sacrifice recall here because they remove many\nupdates aggressively when attackers blend in. In the Byzantine\ngradient case (Figure 5b), gradients are perturbed to create",
                "description": null,
                "id": 190,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            97,
                            938,
                            788
                        ],
                        "page_id": 10
                    }
                ],
                "content": "outliers and noise. Our method combines statistical anomaly tests with gradient clipping, which caps the impact of large or erratic updates and also flags them for low reputation. This keeps precision and recall both high. FedAvg degrades because it averages all updates. Krum and Trimmed Mean improve precision but still show lower recall than our method, since they can discard too many borderline but benign updates under non-IID data. In the gradient scaling case (Figure 5c), some clients scale their gradients to dominate aggregation. Our method maintains high precision and recall because gradient clipping limits the size of each update, and the adaptive threshold reduces the participation of clients whose influence does not align with their reputation. Other robust aggregators improve precision but lose recall when they become too conservative against scaled updates. In the label flip case (Figure 5d), attacks corrupt local labels rather than gradients. Here, performance consistency (r1) is the main signal. Our method monitors how each clip may not always update held-out or global performance and lowers trust when updates repeatedly harm accuracy. This is why both precision and recall remain high. Baselines that depend more on gradient geometry are less effective because they fail clips that always appear as strong outliers in gradient space. Looking across the Figure 5, two patterns explain why FLARE is better. First, multi-dimensional scoring links three views of behavior: performance consistency (r1), statistical anomaly (r2), and temporal behavior (r3). This gives good separation between malicious clients and benign clients with non-IID data. Second, soft exclusion turns scores into smooth weights rather than a hard accept or reject. This keeps useful signal from uncertain clients while reducing the damage from suspicious ones. Adaptive thresholds further align strictness with training progress, and reputation decay prevents short periods of good behavior from resetting trust. The result is a high F1-score with balanced precision and recall in all attack types.",
                "description": null,
                "id": 191,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            793,
                            938,
                            1227
                        ],
                        "page_id": 10
                    }
                ],
                "content": "Sophisticated Attacks. In the ALIE attack case (Figure 5c),\nattackers craft statistically aligned malicious updates that\nmimic the distribution of benign gradients. This is one of\nthe strongest and most deceptive attack types. FLARE still\nmaintains the highest precision and recall, improving F1-\nscore by approximately 25–30% over the best competing\nmethod. Methods such as Krum, FLTrust, or FLAME struggle\nhere because ALIE updates are designed to bypass simple\ndistance-based or clustering-based filtering. FLARE's multi-\ndimensional scoring and temporal tracking allow it to isolate\nthese adaptive, well-camouflaged attackers more reliably. In\nthe SM attack case (Figure 5f), malicious clients generate sub-\ntle, near-normal updates that closely resemble benign behavior.\nThis makes the attack particularly difficult to detect. Despite\nthis subtlety, FLARE achieves the highest recall typically\n15–20% higher than robust baselines and maintains strong\nprecision by combining anomaly scoring with reputation-based\nweighting. Methods that rely solely on gradient geometry fail\nto maintain recall because SM attackers intentionally avoid\ngenerating outliers. FLARE's soft exclusion and adaptive\nthresholds help separate persistent low-impact attackers from\nbenign but noisy clients.",
                "description": null,
                "id": 192,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            536,
                            1232,
                            938,
                            1246
                        ],
                        "page_id": 10
                    }
                ],
                "content": "Figs. 6 to 8 summarize FLARE across datasets (MNIST,",
                "description": null,
                "id": 193,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            927,
                            41,
                            938,
                            53
                        ],
                        "page_id": 11
                    }
                ],
                "content": "12",
                "description": null,
                "id": 194,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            257,
                            88,
                            762,
                            102
                        ],
                        "page_id": 11
                    }
                ],
                "content": "TABLE X: Ablation Study: Test Accuracy (%) with 20% Malicious Clients under α = 0.3",
                "description": null,
                "id": 195,
                "type": "caption"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            102,
                            937,
                            224
                        ],
                        "page_id": 11
                    }
                ],
                "content": "<table><thead><tr><th rowspan=\"2\">Configuration</th><th colspan=\"3\">Label Flip</th><th colspan=\"3\">Byzantine</th><th colspan=\"3\">Gradient Scaling</th><th colspan=\"3\">Adaptive</th><th colspan=\"3\">ALJE</th><th colspan=\"3\">SM Attack</th></tr><tr><th>MNIST</th><th>CIFAR</th><th>SVHN</th><th>MNIST</th><th>CIFAR</th><th>SVHN</th><th>MNIST</th><th>CIFAR</th><th>SVHN</th><th>MNIST</th><th>CIFAR</th><th>SVHN</th><th>MNIST</th><th>CIFAR</th><th>SVHN</th><th>MNIST</th><th>CIFAR</th><th>SVHN</th></tr></thead><tbody><tr><td>Full FLARE</td><td>91.7</td><td>87.5</td><td>83.7</td><td>98.6</td><td>88.6</td><td>86.3</td><td>91.9</td><td>89.4</td><td>85.5</td><td>92.5</td><td>87.0</td><td>83.7</td><td>86.3</td><td>29.3</td><td>22.6</td><td>82.6</td><td>71.5</td><td>51.1</td></tr><tr><td>with Performance Consistency (r<sub>1</sub>)</td><td>87.6</td><td>83.4</td><td>82.2</td><td>86.3</td><td>83.2</td><td>82.0</td><td>86.1</td><td>82.0</td><td>81.7</td><td>85.2</td><td>80.4</td><td>79.6</td><td>78.2</td><td>18.4</td><td>17.3</td><td>79.4</td><td>68.2</td><td>43.6</td></tr><tr><td>with Statistical Anomaly (r<sub>2</sub>)</td><td>88.4</td><td>82.1</td><td>83.0</td><td>84.6</td><td>82.6</td><td>80.1</td><td>83.6</td><td>79.2</td><td>78.6</td><td>83.7</td><td>80.1</td><td>78.3</td><td>72.6</td><td>15.2</td><td>12.3</td><td>77.3</td><td>66.9</td><td>39.8</td></tr><tr><td>with Temporal Behavior (r<sub>3</sub>)</td><td>88.3</td><td>85.4</td><td>83.6</td><td>87.7</td><td>85.0</td><td>83.7</td><td>87.6</td><td>83.9</td><td>83.0</td><td>85.6</td><td>81.4</td><td>80.4</td><td>79.4</td><td>20.6</td><td>15.2</td><td>77.3</td><td>60.1</td><td>45.7</td></tr><tr><td>with Adaptive Threshold</td><td>85.8</td><td>81.9</td><td>80.4</td><td>84.9</td><td>81.9</td><td>80.2</td><td>84.4</td><td>80.8</td><td>79.6</td><td>82.9</td><td>78.5</td><td>77.6</td><td>74.1</td><td>16.8</td><td>13.7</td><td>78.2</td><td>67.5</td><td>40.3</td></tr><tr><td>with Soft Exclusion</td><td>83.6</td><td>79.8</td><td>78.2</td><td>82.6</td><td>79.9</td><td>78.0</td><td>82.1</td><td>78.0</td><td>77.3</td><td>80.6</td><td>76.1</td><td>75.1</td><td>69.8</td><td>13.1</td><td>11.4</td><td>75.9</td><td>64.3</td><td>37.6</td></tr><tr><td>with Reputation Decay</td><td>87.0</td><td>83.5</td><td>81.4</td><td>86.2</td><td>82.6</td><td>82.1</td><td>86.5</td><td>82.8</td><td>80.5</td><td>84.7</td><td>80.2</td><td>79.1</td><td>76.9</td><td>17.9</td><td>14.8</td><td>70.1</td><td>69.6</td><td>42.5</td></tr><tr><td>with Privacy-Preserving</td><td>90.0</td><td>85.8</td><td>83.9</td><td>89.1</td><td>85.9</td><td>85.2</td><td>87.6</td><td>84.5</td><td>83.6</td><td>87.0</td><td>82.9</td><td>82.4</td><td>82.7</td><td>21.1</td><td>18.6</td><td>73.8</td><td>60.4</td><td>46.7</td></tr><tr><td>with Gradient Clipping</td><td>87.9</td><td>83.8</td><td>82.4</td><td>87.0</td><td>84.0</td><td>82.9</td><td>85.3</td><td>81.5</td><td>80.4</td><td>86.0</td><td>81.7</td><td>80.5</td><td>77.5</td><td>18.3</td><td>15.1</td><td>79.7</td><td>69.1</td><td>41.9</td></tr><tr><td>with Multi-dimensional Scoring</td><td>84.2</td><td>79.9</td><td>78.8</td><td>82.8</td><td>80.6</td><td>78.6</td><td>82.8</td><td>79.3</td><td>77.2</td><td>81.1</td><td>76.6</td><td>75.6</td><td>71.9</td><td>14.6</td><td>12.2</td><td>78.5</td><td>68.8</td><td>40.4</td></tr></tbody></table>",
                "description": null,
                "id": 196,
                "type": "table"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            261,
                            496,
                            607
                        ],
                        "page_id": 11
                    }
                ],
                "content": null,
                "description": "Four graphs display upward trending lines representing test accuracy versus communication round for various models on MNIST and CIFAR-10 datasets.",
                "id": 197,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            115,
                            614,
                            257,
                            628
                        ],
                        "page_id": 11
                    }
                ],
                "content": "Adaptive Attack on SVHN",
                "description": null,
                "id": 198,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            320,
                            614,
                            472,
                            628
                        ],
                        "page_id": 11
                    }
                ],
                "content": "(f) Byzantine Attack on SVHN",
                "description": null,
                "id": 199,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            629,
                            500,
                            717
                        ],
                        "page_id": 11
                    }
                ],
                "content": "Fig. 6: Convergence under attacks on MNIST, CIFAR-10, and SVHN (non-\nID, Dirichlet $\\alpha=0.3$ ). Figures 6b , 6c , and 6e show test accuracy over\ncommunication rounds for non-IID data under Adaptive attacks. Figures 6b\n6d , and 6f show test accuracy under Byzantine gradient attacks. FLARE\nconsistently converges in the fewest rounds and attains the highest (or near-\nhighest) final accuracy across datasets.",
                "description": null,
                "id": 200,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            722,
                            496,
                            1092
                        ],
                        "page_id": 11
                    }
                ],
                "content": null,
                "description": "Four graphs display line charts with multiple colored lines, each labeled with text, comparing test accuracy against communication rounds.",
                "id": 201,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            1093,
                            500,
                            1182
                        ],
                        "page_id": 11
                    }
                ],
                "content": "Fig. 7: Convergence and robustness under sophisticated attacks on MNIST, CIFAR-10, and SVHN (non-IID, Dirichlet $\\alpha=0.3$ ). Figures 7a , 7c , and 7e\nshow the Statistical Mimicry attack. Figures 7b , 7d , and 7f show the ALIE\nattack. Test accuracy is shown over communication rounds. FLARE converges\nin the fewest rounds and keeps the highest or near-highest accuracy across\nheterogeneity levels on all datasets.",
                "description": null,
                "id": 202,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            1201,
                            500,
                            1235
                        ],
                        "page_id": 11
                    }
                ],
                "content": "CIFAR-10, SVHN), both without attacks and under multiple attack types. The main result is that our method achieves the",
                "description": null,
                "id": 203,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            261,
                            938,
                            638
                        ],
                        "page_id": 11
                    }
                ],
                "content": null,
                "description": "Four graphs display curves representing test accuracy versus communication rounds, with different colored lines indicating various methods.",
                "id": 204,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            641,
                            938,
                            666
                        ],
                        "page_id": 11
                    }
                ],
                "content": "(e) IID data without any attack on SVHN (f) Non-IID data without any attack on SVHN",
                "description": null,
                "id": 205,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            669,
                            938,
                            757
                        ],
                        "page_id": 11
                    }
                ],
                "content": "Fig. 8: Convergence and non-IID robustness without attacks on MNIST, CIFAR-10, and SVHN. Figures 8a, 8c, and 8e display the test accuracy over communication rounds for IID data. The legend indicates the first round at which each method achieves the study's target accuracy (Conv). Figures 8d, 8e, and 8f report final test accuracy under non-IID data generated by a Dirichlet sampler with parameter $\\alpha$ (smaller $\\alpha$ means stronger heterogeneity).",
                "description": null,
                "id": 206,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            775,
                            938,
                            810
                        ],
                        "page_id": 11
                    }
                ],
                "content": "target accuracy in fewer rounds and maintains higher final accuracy. This holds for both clean IID data and non-IID data.",
                "description": null,
                "id": 207,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            832,
                            938,
                            1246
                        ],
                        "page_id": 11
                    }
                ],
                "content": "Under attacks (Figs. 6 and 7), non-IID $\\alpha=0.3$ ). In the\nadaptive and Byzantine attacks in Figure 6 for MNIST, CIFAR-\n10, and SVHN, our method reaches the target accuracy in\nfewer rounds and maintains a higher trajectory. Adaptive\nattackers change behavior across rounds to regain trust. The\ntemporal view (r3) and reputation decay track such changes,\npreventing the quick recovery of reputation. At the same time,\nthe anomaly score (r2) maintains high precision by detecting\nunusual gradients, and performance consistency (r1) mitigates\nthe influence of clients whose updates repeatedly hinder global\nprogress. Soft exclusion turns these signals into continuous\nweights, so suspicious clients are down-weighted immediately,\nwhile borderline but benign clients can still contribute some\ninformation. In the Sophisticated attack subfigures of Figure 7,\nour method again reaches the target faster and ends at a higher\nvalue. Byzantine gradients create noise and outliers. Gradient\nclipping limits the size of each update, helping protect against\nextreme values. The anomaly score then flags these patterns as\nlow-reputation. Because down-weighting is continuous rather\nthan a hard reject, the aggregator preserves enough diversity to\nkeep learning stable, while still limiting harm from corrupted",
                "description": null,
                "id": 208,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            929,
                            47,
                            937,
                            63
                        ],
                        "page_id": 12
                    }
                ],
                "content": "",
                "description": null,
                "id": 209,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            91,
                            500,
                            150
                        ],
                        "page_id": 12
                    }
                ],
                "content": "updates. This is visible as a smoother, faster rise in the accuracy curve compared to methods that prune aggressively or average all updates.",
                "description": null,
                "id": 210,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            156,
                            509,
                            750
                        ],
                        "page_id": 12
                    }
                ],
                "content": "Without attacks (Figure 8). On clean IID data in Figure 8a,\n8c and 8e, the curve for FLARE rises faster and reaches the\ntarget in the fewest rounds. The legend shows the first round at\nwhich each method hits the target accuracy. The numbers are\napproximately 58 rounds on MNIST, 70 on CIFAR-10, and 77\non SVHN for our method, whereas the baselines require more\nrounds. Two design choices explain this speed. First, multi-\ndimensional scoring with soft exclusion reduces the weight of\nunstable or low-quality updates even when there is no attack.\nThis reduces gradient variance at the server, leading to faster\nimprovement per round. Second, the adaptive threshold limits\nearly participation by clients who are not yet consistent, then\nallows them to contribute more once their behavior stabilizes.\nThese steps focus the aggregation on the most helpful updates\nin the early phase when the model is most sensitive. On\nclean non-IID data in Figure 8b, 8d, and 8f, accuracy is\nreported at different levels of heterogeneity controlled by the\nDirichlet parameter $\\alpha$ . As $\\alpha$ decreases and client data become\nmore skewed, all methods lose some accuracy, but FLARE\nremains highest or tied for highest across the full range on\nall three datasets. The reason is that the method separates\nnatural non-IID drift from harmful behavior. Performance\nconsistency (r1) measures how a client's update affects held-\nout or global performance, so rare but valid updates are not\npenalized. Statistical anomaly scoring (r2) focuses on true\noutliers in gradient or metric space. Temporal behavior (r3)\nand reputation decay reduce the influence of clients that are\ninconsistent across rounds. Soft exclusion then converts these\nscores into smooth weights, which keep the useful signal from\nclients with rare labels instead of removing them entirely.",
                "description": null,
                "id": 211,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            754,
                            510,
                            990
                        ],
                        "page_id": 12
                    }
                ],
                "content": "Across figures, the same mechanism explains the consistent advantage. Front-end discrimination from the three scores (r1, r2, r3) identifies helpful versus harmful behavior. Aggregation control through soft exclusion and gradient clipping bounds the influence of uncertain or adversarial clients without discarding useful signal. Long-term resilience through reputation decay and temporal tracking prevents on-off strategies that try to rebuild trust between attacks. These parts work together in clean IID data, in non-IID data, and under attacks. As a result, the method uses more of the good signal in each round, reduces the effect of the bad signal, and reaches the target accuracy sooner while keeping strong final accuracy.",
                "description": null,
                "id": 212,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            232,
                            1022,
                            351,
                            1037
                        ],
                        "page_id": 12
                    }
                ],
                "content": "V. CONCLUSION",
                "description": null,
                "id": 213,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            82,
                            1050,
                            510,
                            1246
                        ],
                        "page_id": 12
                    }
                ],
                "content": "In this work, we introduce FLARE, a practical defense for\nfederated learning that joins multi-dimensional client scoring,\nsoft exclusion, adaptive thresholds, reputation decay, gradient\nclipping, and privacy preservation into a single aggregation\npipeline. The design goal was to separate harmful clients\nfrom benign but heterogeneous clients, limit the influence\nof uncertain updates without discarding useful signals, and\nachieve this with a low runtime cost. Across image bench-\nmarks (MNIST, CIFAR-10, SVHN) and five common attack\ntypes, the method met these goals. The detection figure and",
                "description": null,
                "id": 214,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            97,
                            947,
                            410
                        ],
                        "page_id": 12
                    }
                ],
                "content": "Table IX demonstrate high precision, recall, and F1-scores at 200 rounds, including in the adaptive setting where attackers change their behavior over time. Convergence studies without attacks show that FLARE reaches the target accuracy in fewer rounds than all baselines on every dataset. Under non-IID data, accuracy remains the highest or near the highest as heterogeneity increases. As the fraction of malicious clients increases from 5% to 30%, the full system's accuracy curve is consistently the flattest. The optimization and systems results are also favorable. We demonstrate stable weighted average loss at convergence across all attacks and datasets, indicating that the defense does not hinder learning while suppressing harmful contributions. The cumulative aggregation time after 200 rounds changes only slightly across conditions, indicating that the extra scoring and reweighting steps introduce little overhead compared to standard aggregation.",
                "description": null,
                "id": 215,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            415,
                            947,
                            610
                        ],
                        "page_id": 12
                    }
                ],
                "content": "Future work. There are several promising directions. A first direction is personalization-aware robustness, where reputation interacts with client similarity to avoid penalizing users with rare but valid data. A second direction is broader threat coverage, including backdoors, model replacement, and privacy-accuracy trade-offs under stronger privacy mechanisms. A third direction is systems integration for cross-device and cross-silo settings with partial participation, stragglers, and communication constraints, where reputation can guide both scheduling and aggregation.",
                "description": null,
                "id": 216,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            658,
                            648,
                            803,
                            660
                        ],
                        "page_id": 12
                    }
                ],
                "content": "ACKNOWLEDGMENT",
                "description": null,
                "id": 217,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            519,
                            676,
                            937,
                            772
                        ],
                        "page_id": 12
                    }
                ],
                "content": "This article is an output of a project supported by the\nRecovery and Resilience Plan of the Slovak Republic under the\ncall 'Transformation and Innovation Consortia' (project code:\n09I02-03-V01-00012). The author contributes to this research\nas part of a consortium coordinated by InterWay, a.s.",
                "description": null,
                "id": 218,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            683,
                            809,
                            775,
                            824
                        ],
                        "page_id": 12
                    }
                ],
                "content": "REFERENCES",
                "description": null,
                "id": 219,
                "type": "section_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            843,
                            937,
                            885
                        ],
                        "page_id": 12
                    }
                ],
                "content": "[1] C. Guo, X. Zhang, L. Zhang, C. Gong, H. Xu, and Z. Han, \"Reputation-\nbased federated learning algorithm for fairness and security in internet\nof vehicles,\" IEEE Internet of Things Journal, 2025.",
                "description": null,
                "id": 220,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            887,
                            937,
                            930
                        ],
                        "page_id": 12
                    }
                ],
                "content": "[2] L. Shi, Y. Gao, C. Chen, S. Huang, J. Zhao, X. Hu, and V. C.\nLeung, “Fedmar: A privacy-preserving and robust server-side multi-stage\nfederated learning,” IEEE Internet of Things Journal, 2025.",
                "description": null,
                "id": 221,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            933,
                            937,
                            990
                        ],
                        "page_id": 12
                    }
                ],
                "content": "[3] J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang, \"Incentive mech-\nanism for reliable federated learning: A joint optimization approach\nto combining reputation and contract theory,\" IEEE Internet of Things\nJournal, vol. 6, no. 6, pp. 10700-10714, 2019.",
                "description": null,
                "id": 222,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            993,
                            937,
                            1065
                        ],
                        "page_id": 12
                    }
                ],
                "content": "[4] A. Younesi, E. Oustad, M. Ansari, T. Fahringer, and R. Buya,\n“Healthcare 5.0: An industry 5.0 perspective for next-generation\nmedical systems with synergistic integration of iot, ai, and 6g,”\nInternet of Things, vol. 35, p. 101815, 2026. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S2542660525003294",
                "description": null,
                "id": 223,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            1068,
                            937,
                            1171
                        ],
                        "page_id": 12
                    }
                ],
                "content": "[5] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y\nArcas, \"Communication-Efficient Learning of Deep Networks from\nDecentralized Data,\" in Proceedings of the 20th International\nConference on Artificial Intelligence and Statistics, ser. Proceedings\nof Machine Learning Research, A. Singh and J. Zhu, Eds., vol. 54,\nPMLR, 20–22 Apr 2017, pp. 1273–1282. [Online]. Available:\nhttps://proceedings.mlr.press/v54/mcmahan17a.html",
                "description": null,
                "id": 224,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            1173,
                            937,
                            1215
                        ],
                        "page_id": 12
                    }
                ],
                "content": "[6] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, \"Federated learning:\nChallenges, methods, and future directions,\" IEEE signal processing\nmagazine, vol. 37, no. 3, pp. 50-60, 2020.",
                "description": null,
                "id": 225,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            526,
                            1218,
                            937,
                            1246
                        ],
                        "page_id": 12
                    }
                ],
                "content": "[7] P. Kairouz et al., “Advances and open problems in federated learning,\" 2021. [Online]. Available: https://arxiv.org/abs/1912.04977",
                "description": null,
                "id": 226,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            927,
                            41,
                            938,
                            53
                        ],
                        "page_id": 13
                    }
                ],
                "content": "14",
                "description": null,
                "id": 227,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            89,
                            97,
                            500,
                            156
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[8] A. Younesi, M. Barati, M. Ansari, M. A. Fazli, A. Ejlali, M. Shafique,\nand J. Henkel, “Cnn-feet: Efficient cnn in federated learning for energy-\nefficiency in emerging fault-tolerant fog-edge environments,” Authora\nPreprints, 2024.",
                "description": null,
                "id": 228,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            89,
                            156,
                            500,
                            187
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[9] L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”\narXiv preprint arXiv:2003.02133, 2020.",
                "description": null,
                "id": 229,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            187,
                            500,
                            230
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[10] E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, \"How to\nbackdoor federated learning,\" in International conference on artificial\nintelligence and statistics. PMLR, 2020, pp. 2938-2948.",
                "description": null,
                "id": 230,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            231,
                            500,
                            292
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[11] T.-P. Pham, S. Ristov, and T. Fahringer, “Performance and behavior\ncharacterization of amazon ec2 spot instances,” in 2018 IEEE 11th\nInternational Conference on Cloud Computing (CLOUD), 2018, pp. 73–\n81.",
                "description": null,
                "id": 231,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            292,
                            500,
                            337
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[12] T.-P. Pham and T. Fahringer, \"Evolutionary multi-objective workflow scheduling for volatile resources in the cloud,\" IEEE Transactions on\nCloud Computing, vol. 10, no. 3, pp. 1780–1791, 2022.",
                "description": null,
                "id": 232,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            339,
                            500,
                            383
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[13] T. Le and S. Moothedath, “Byzantine resilient federated multi-task\nrepresentation learning,” 2025. [Online]. Available: https://arxiv.org/abs/\n2503.19209",
                "description": null,
                "id": 233,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            383,
                            500,
                            443
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[14] W. Liu, L. Chen, and W. Zhang, “Decentralized federated learning:\nBalancing communication and computing costs,” IEEE Transactions on\nSignal and Information Processing over Networks, vol. 8, pp. 131–143,\n2022.",
                "description": null,
                "id": 234,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            443,
                            500,
                            489
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[15] J. Chen, H. Yan, Z. Liu, M. Zhang, H. Xiong, and S. Yu, “When federated learning meets privacy-preserving computation,” ACM Computing Surveys, vol. 56, no. 12, pp. 1–36, 2024.",
                "description": null,
                "id": 235,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            489,
                            500,
                            550
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[16] K. N. Kumar, C. K. Mohan, and L. R. Cenkera maddi, “The impact of\nadversarial attacks on federated learning: A survey,” IEEE Transactions\non Pattern Analysis and Machine Intelligence, vol. 46, no. 5, pp. 2672—\n2691, 2023.",
                "description": null,
                "id": 236,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            550,
                            500,
                            610
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[17] E.-M. El Mhamdi, R. Guerraoui, and S. L. A. Rouault, “Distributed momentum for byzantine-resilient stochastic gradient descent,” in 9th\nInternational Conference on Learning Representations, ICLR, 2021, pp.\n4–8.",
                "description": null,
                "id": 237,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            610,
                            500,
                            670
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[18] S. Farhadkhani, R. Guerraoui, N. Gupta, R. Pinot, and J. Stephan,\n\"Byzantine machine learning made easy by resilient averaging of mo-\nmentums,\" in International Conference on Machine Learning, PMLR,\n2022, pp. 6246–6283.",
                "description": null,
                "id": 238,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            670,
                            500,
                            716
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[19] D. Yin, Y. Chen, R. Kannan, and P. Bartlett, \"Byzantine-robust dis-\ntributed learning: Towards optimal statistical rates,\" in International\nconference on machine learning. Pmlr, 2018, pp. 5650–5659.",
                "description": null,
                "id": 239,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            716,
                            500,
                            762
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[20] D. Data and S. N. Diggavi, \"Byzantine-resilient high-dimensional fed-\nerated learning,\" IEEE Transactions on Information Theory, vol. 69,\nno. 10, pp. 6639-6670, 2023.",
                "description": null,
                "id": 240,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            762,
                            500,
                            807
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[21] P. Blanchard, E. M. El Mhamdi, R. Guerraoui, and J. Stainer, \"Ma-\nchine learning with adversaries: Byzantine tolerant gradient descent,\"\nAdvances in neural information processing systems, vol. 30, 2017.",
                "description": null,
                "id": 241,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            809,
                            500,
                            868
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[22] M. Fang, Z. Zhang, Hairi, P. Khanduri, J. Liu, S. Lu, Y. Liu, and\nN. Gong, “Byzantine-robust decentralized federated learning,” in Pro-\nceedings of the 2024 on ACM SIGSAC Conference on Computer and\nCommunications Security, 2024, pp. 2874–2888.",
                "description": null,
                "id": 242,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            869,
                            500,
                            928
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[23] B. Zhao, P. Sun, T. Wang, and K. Jiang, “Fedinv: Byzantine-robust\nfederated learning by inverting local model updates,” in Proceedings\nof the AAAI Conference on Artificial Intelligence, vol. 36, no. 8, 2022,\npp. 9171–9179.",
                "description": null,
                "id": 243,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            928,
                            500,
                            989
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[24] Q. Dong, S. Yang, Z. Dai, Y. Gao, S. Wang, Y. Cao, A. Fu, and W. Susilo,\n“Careft: Contribution guided byzantine-robust federated learning,” IEEE\nTransactions on Information Forensics and Security, vol. 19, pp. 9714—\n9729, 2024.",
                "description": null,
                "id": 244,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            989,
                            500,
                            1049
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[25] C. Guo, X. Zhang, L. Zhang, C. Gong, H. Xu, and Z. Han, “Reputation-based federated learning algorithm for fairness and security in internet of\nvehicles,” IEEE Internet of Things Journal, vol. 12, no. 21, pp. 44 502—\n44 520, 2025.",
                "description": null,
                "id": 245,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            1049,
                            500,
                            1109
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[26] Y. Zhao, J. Zhao, M. Yang, T. Wang, N. Wang, L. Lyu, D. Niyato,\nand K.-Y. Lam, “Local differential privacy-based federated learning for\ninternet of things,” IEEE Internet of Things Journal, vol. 8, no. 11, pp.\n8836–8853, 2020.",
                "description": null,
                "id": 246,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            1111,
                            500,
                            1155
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[27] I. M. Penalva, E. T. M. Beltrán, M. G. Pérez, and A. H. Celdrán,\n\"Repunet: A reputation system for mitigating malicious clients in dfl,\"\narXiv preprint arXiv:2506.19892, 2025.",
                "description": null,
                "id": 247,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            1155,
                            500,
                            1215
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[28] X. Tan, W. C. Ng, W. Y. B. Lim, Z. Xiong, D. Niyato, and H. Yu,\n“Reputation-aware federated learning client selection based on stochastic\ninteger programming,” IEEE Transactions on Big Data, vol. 10, no. 6,\npp. 953–964, 2022.",
                "description": null,
                "id": 248,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            80,
                            1215,
                            500,
                            1246
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[29] N. M. Al-Maslamani, M. Abdallah, and B. S. Ciftler, \"Reputation-aware multi-agent drl for secure hierarchical federated learning in iot,\" IEEE",
                "description": null,
                "id": 249,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            550,
                            97,
                            938,
                            128
                        ],
                        "page_id": 13
                    }
                ],
                "content": "Open Journal of the Communications Society, vol. 4, pp. 1274–1284, 2023",
                "description": null,
                "id": 250,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            128,
                            938,
                            187
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[30] C. Fu, X. Zhang, S. Ji., J. Chen, J. Wu, S. Guo, J. Zhou, A. X. Liu, and\nT. Wang, “Label inference attacks against vertical federated learning,”\nin 31st USENIX security symposium (USENIX Security 22), 2022, pp.\n1397–1414.",
                "description": null,
                "id": 251,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            187,
                            938,
                            245
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[31] X. Gui, G. Yu, J. Wang, Z. Yan, W. Wang, C. Domeniconi, and L. Cui,\n\"Sophon: Byzantine-robust federated learning via dual trust mechanism,\"\nIEEE Transactions on Dependable and Secure Computing, pp. 1–12,\n2025.",
                "description": null,
                "id": 252,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            246,
                            938,
                            305
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[32] Y. Mao, Z. Ye, X. Yuan, and S. Zhong, “Secure model aggregation against poisoning attacks for cross-silo federated learning with robust-\nness and fairness,” IEEE Transactions on Information Forensics and\nSecurity, vol. 19, pp. 6321–6336, 2024.",
                "description": null,
                "id": 253,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            305,
                            938,
                            364
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[33] N. M. Al-Maslamani, B. S. Ciftler, M. Abdallah, and M. M. Mahmoud,\n“Toward secure federated learning for IoT using drl-enabled reputation\nmechanism,” IEEE Internet of Things Journal, vol. 9, no. 21, pp. 21 971—\n21 983, 2022.",
                "description": null,
                "id": 254,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            364,
                            938,
                            424
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[34] Z. Luan, W. Li, M. Liu, and B. Chen, “Robust federated learning:\nMaximum currentropy aggregation against byzantine attacks,” IEEE\nTransactions on Neural Networks and Learning Systems, vol. 36, no. 1,\npp. 62–75, 2025.",
                "description": null,
                "id": 255,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            424,
                            938,
                            485
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[35] X. Mu, K. Cheng, Y. Shen, X. Li, Z. Chang, T. Zhang, and X. Ma,\n“Feddme: Efficient and robust federated learning via detecting malicious\nclients,” IEEE Transactions on Dependable and Secure Computing,\nvol. 21, no. 6, pp. 5259–5274, 2024.",
                "description": null,
                "id": 256,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            485,
                            938,
                            529
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[36] S. Huang, Y. Li, C. Chen, Y. Gao, and X. Hu, “Fedid: Enhancing\nfederated learning security through dynamic identification,” IEEE Trans-\nactions on Pattern Analysis and Machine Intelligence, 2025.",
                "description": null,
                "id": 257,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            529,
                            938,
                            588
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[37] C. Sandeepa, B. Siniarski, S. Wang, and M. Liyanage, “Sherpa: Ex-\nplainable robust algorithms for privacy-preserved federated learning in\nfuture networks to defend against data poisoning attacks,” in 2024 IEEE\nSymposium on Security and Privacy (SP), IEEE, 2024, pp. 4772–4790.",
                "description": null,
                "id": 258,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            589,
                            938,
                            648
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[38] R. Xu, S. Gao, C. Li, J. Joshi, and J. Li, “Dual defense: Enhancing pri-\nvacy and mitigating poisoning attacks in federated learning,” Advances\nin Neural Information Processing Systems, vol. 37, pp. 70476–70498,\n2024.",
                "description": null,
                "id": 259,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            648,
                            938,
                            692
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[39] Y. Tao, S. Cui, W. Xu, H. Yin, D. Yu, W. Liang, and X. Cheng,\n“Byzantine-resilient federated learning at edge,” IEEE Transactions on\nComputers, vol. 72, no. 9, pp. 2600–2614, 2023.",
                "description": null,
                "id": 260,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            692,
                            938,
                            753
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[40] F. Sattler, K.-R. Müller, T. Wiegand, and W. Samek, “On the byzantine\nrobustness of clustered federated learning,” in ICASSP 2020 - 2020 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing\n(ICASSP), 2020, pp. 8861–8865.",
                "description": null,
                "id": 261,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            753,
                            938,
                            797
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[41] M. Baruch, G. Baruch, and Y. Goldberg, “A little is enough:\nCircumventing defenses for distributed learning,” 2019. [Online].\nAvailable: https://arxiv.org/abs/1902.06156",
                "description": null,
                "id": 262,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            798,
                            938,
                            872
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[42] S. Dehnavi, H. R. Faragardi, M. Kargahi, and T. Fahringer, “A\nreliability-aware resource provisioning scheme for real-time industrial\napplications in a fog-integrated smart factory,” Microprocessors\nand Microsystems, vol. 70, pp. 1–14, 2019. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S0141933118304629",
                "description": null,
                "id": 263,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            874,
                            938,
                            918
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[43] M. Fang, X. Cao, J. Jia, and N. Gong, \"Local model poisoning attacks\nto {Byzantine-Robust} federated learning,\" in 29th USENIX security\nsymposium (USENIX Security 20), 2020, pp. 1605–1622.",
                "description": null,
                "id": 264,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            918,
                            938,
                            977
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[44] H. Zeng, J. Li, J. Lou, S. Yuan, C. Wu, W. Zhao, S. Wu, and Z. Wang,\n“Bsr-fl: An efficient byzantine-robust privacy-preserving federated learn-\ning framework,” IEEE Transactions on Computers, vol. 73, no. 8, pp.\n2096–2110, 2024.",
                "description": null,
                "id": 265,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            977,
                            938,
                            1022
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[45] H. Kasyap and S. Tripathi, “Privacy-preserving and byzantine-robust federated learning framework using permissioned blockchain,” Expert\nsystems with applications, vol. 238, p. 122210, 2024.",
                "description": null,
                "id": 266,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1022,
                            938,
                            1068
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[46] X. Gu, M. Li, and L. Xiong. \"Dp-brem: differentially-private and\nbyzantine-robust federated learning with client momentum,\" arXiv\npreprint arXiv:2306.12608, 2023.",
                "description": null,
                "id": 267,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1068,
                            938,
                            1127
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[47] Z. Jiang, P. Ye, S. He, W. Wang, R. Chen, and B. Li, “Lotto: secure participant selection against adversarial servers in federated learning,”\nin 33rd USENIX Security Symposium (USENIX Security 24), 2024, pp.\n343–360.",
                "description": null,
                "id": 268,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1127,
                            938,
                            1171
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[48] F. Zhao, Y. Xie, X. Ren, B. Ding, S. Yang, and Y. Li, \"Understanding\nbyzantine robustness in federated learning with a black-box server,\"\n2024. [Online]. Available: https://arxiv.org/abs/2408.06042",
                "description": null,
                "id": 269,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1173,
                            938,
                            1215
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[49] K. Yue, R. Jin, C.-W. Wong, and H. Dai, \"Advancing hybrid defense for byzantine attacks in federated learning,\" 2025. [Online]. Available:\nhttps://arxiv.org/abs/2409.06474",
                "description": null,
                "id": 270,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            1217,
                            938,
                            1246
                        ],
                        "page_id": 13
                    }
                ],
                "content": "[50] A. Deshmukh, “Byzantine-robust federated learning: An overview with focus on developing sybil-based attacks to backdoor augmented",
                "description": null,
                "id": 271,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            927,
                            41,
                            938,
                            53
                        ],
                        "page_id": 14
                    }
                ],
                "content": "15",
                "description": null,
                "id": 272,
                "type": "page_header"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            110,
                            97,
                            500,
                            127
                        ],
                        "page_id": 14
                    }
                ],
                "content": "secure aggregation protocols,\" 2024. [Online]. Available: https://arxiv.org/abs/2410.22680",
                "description": null,
                "id": 273,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            128,
                            500,
                            171
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[5] G. Syros, A. Suri, F. Koushanfar, C. Nita-Rotaru, and A. Oprea, \"Drop:\nPoison dilution via knowledge distillation for federated learning,\" 2025.\n[Online]. Available: https://arxiv.org/abs/2502.07011",
                "description": null,
                "id": 274,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            174,
                            500,
                            217
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[52] Y. Xie, M. Fang, and N. Z. Gong, “Model poisoning attacks to federated learning via multi-round consistency,” 2025. [Online].\nAvailable: https://arxiv.org/abs/2404.15611",
                "description": null,
                "id": 275,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            218,
                            500,
                            275
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[53] J. Le, D. Zhang, X. Lei, L. Jiao, K. Zeng, and X. Liao, “Privacy-\npreserving federated learning with malicious clients and honest-but-\ncurious servers,” IEEE Transactions on Information Forensics and\nSecurity, vol. 18, pp. 4329–4344, 2023.",
                "description": null,
                "id": 276,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            277,
                            500,
                            334
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[54] F. Nadeem, R. Prodan, and T. Fahringer, \"Characterizing, modeling\nand predicting dynamic resource availability in a large scale multi-\npurpose grid,\" in 2008 Eighth IEEE International Symposium on Cluster\nComputing and the Grid (CCGRID), 2008, pp. 348–357.",
                "description": null,
                "id": 277,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            336,
                            500,
                            379
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[55] J. C. Duchi, M. I. Jordan, and M. J. Wainwright, \"Local privacy and\nstatistical minimax rates,\" in 2013 IEEE 54th Annual Symposium on\nFoundations of Computer Science, 2013, pp. 429-438.",
                "description": null,
                "id": 278,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            382,
                            500,
                            424
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[56] C. Dwork and A. Roth, “The algorithmic foundations of differential\nprivacy,” Found. Trends Theor. Comput. Sci., vol. 9, no. 3-4, p. 211–407,\nAug. 2014. [Online]. Available: https://doi.org/10.1561/0400000042",
                "description": null,
                "id": 279,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            426,
                            500,
                            468
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[57] Q. Li, Y. Diao, Q. Chen, and B. He, “Federated learning on non-iid data silos: An experimental study,” in 2022 IEEE 38th international conference on data engineering (ICDE). IEEE, 2022, pp. 965–978.",
                "description": null,
                "id": 280,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            471,
                            500,
                            514
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[58] S. Liang, J. Huang, J. Hong, D. Zeng, J. Zhou, and Z. Xu, “Fednoisy:\nFederated noisy label learning benchmark,” 2025. [Online]. Available:\nhttps://arxiv.org/abs/2306.11650",
                "description": null,
                "id": 281,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            516,
                            500,
                            544
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[59] A. Krizhevsky, G. Hinton et al., \"Learning multiple layers of features from tiny images,\" 2009.",
                "description": null,
                "id": 282,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            547,
                            500,
                            589
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[60] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning\napplied to document recognition,” Proceedings of the IEEE, vol. 86,\nno. 11, pp. 2278–2324, 2002.",
                "description": null,
                "id": 283,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            591,
                            500,
                            650
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[61] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, A. Y. Ng et al.,\n\"Reading digits in natural images with unsupervised feature learning,\"\nin NIPS workshop on deep learning and unsupervised feature learning,\nvol. 2011, no. 5. Granada, 2011, p. 7.",
                "description": null,
                "id": 284,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            651,
                            500,
                            694
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[62] H. Zhang, Y. Liu, X. He, J. Wu, T. Cong, and X. Huang, “Sok:\nBenchmarking poisoning attacks and defenses in federated learning,”\n2025. [Online]. Available: https://arxiv.org/abs/2502.03801",
                "description": null,
                "id": 285,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            695,
                            500,
                            738
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[63] X. Cao, M. Fang, J. Liu, and N. Z. Gong, “Fltrust: Byzantine-\nrobust federated learning via trust bootstrapping,” arXiv preprint\narXiv:2012.13995, 2020.",
                "description": null,
                "id": 286,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            741,
                            500,
                            798
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[64] T. D. Nguyen, P. Rieger, H. Chen, H. Yalame, H. Möllering, H. Fer-\neidooni, S. Marchal, M. Miettinen, A. Mirhoseini, S. Zeitouni et al.,\n\"\\{FLAME}: Taming backdoors in federated learning,\" in 31st USENIX\nSecurity Symposium (USENIX Security 22), 2022, pp. 1415–1432.",
                "description": null,
                "id": 287,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            800,
                            500,
                            844
                        ],
                        "page_id": 14
                    }
                ],
                "content": "[65] J. So, B. Güler, and A. S. Avestimehr, \"Byzantine-resilient secure\nfederated learning,\" IEEE Journal on Selected Areas in Communications,\nvol. 39, no. 7, pp. 2168–2181, 2021.",
                "description": null,
                "id": 288,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            217,
                            994,
                            500,
                            1143
                        ],
                        "page_id": 14
                    }
                ],
                "content": "Abolfazl Younesi (Student Member, IEEE) is cur-\nrently pursuing a PhD at the University of Inns-\nbruck. He is a member of the Distributed and\nParallel Systems Group (DPS) at the Department\nof Computer Science. He is working on Euro-\npean Union projects. His research interests include\nDistributed Systems, Stream Processing, Federated\nLearning, and the Computing Continuum, with a\nfocus on intelligent resource management, time-\nsensitive scheduling, and compute optimization.",
                "description": null,
                "id": 289,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            83,
                            997,
                            201,
                            1151
                        ],
                        "page_id": 14
                    }
                ],
                "content": null,
                "description": "A man with dark hair and a short beard looks directly at the camera against a plain background.",
                "id": 290,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            657,
                            97,
                            938,
                            186
                        ],
                        "page_id": 14
                    }
                ],
                "content": "Leon Kiss Leon Kiss is currently pursuing a BSc\nin Computer Science at the University of Innsbruck.\nHe works with the Distributed and Parallel Systems\nGroup (DPS) in the Department of Computer Sci-\nence, exploring the challenges of distributed learn-\ning, particularly federated and split learning.",
                "description": null,
                "id": 291,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            108,
                            639,
                            250
                        ],
                        "page_id": 14
                    }
                ],
                "content": null,
                "description": "A young man with dark hair, a beard, and green earrings is centered in a close-up portrait.",
                "id": 292,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            657,
                            393,
                            938,
                            544
                        ],
                        "page_id": 14
                    }
                ],
                "content": "Zahra Najafabadi Samani received her PhD degree from the University of Klagenfurt, Austria, in 2023. She has been a postdoctoral researcher and university assistant since 2023 in the Distributed and Parallel Systems group at the University of Innsbruck, Austria. She has actively contributed to several national and European Union projects. Her main research interests include resource manage-ment and performance optimization in cloud, fog, and edge computing.",
                "description": null,
                "id": 293,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            410,
                            641,
                            530
                        ],
                        "page_id": 14
                    }
                ],
                "content": null,
                "description": "A woman with dark hair and a black top smiles directly at the camera in a head-and-shoulders portrait.",
                "id": 294,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            657,
                            701,
                            938,
                            866
                        ],
                        "page_id": 14
                    }
                ],
                "content": "Juan Aznar Poveda received his Ph.D. degree in\nTelecommunications Engineering from the Technical\nUniversity of Cartagena, Spain, in 2022. He was\nawarded the prize “Liberalization of Telecommuni-\ncations” (national level) for the best B.Sc. thesis in\n2016. He is currently a postdoctoral researcher at\nthe Distributed and Parallel Systems group of the\nUniversity of Innsbruck, Austria. His research in-\nterests include Distributed Systems, Cyber-Physical\nSystems (CPS), Internet of Things, Artificial Intelli-\ngence, and Wireless networks and communications.",
                "description": null,
                "id": 295,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            518,
                            703,
                            641,
                            854
                        ],
                        "page_id": 14
                    }
                ],
                "content": null,
                "description": "A man with dark hair and glasses smiles at the camera against a blurred outdoor background.",
                "id": 296,
                "type": "figure"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            657,
                            1009,
                            938,
                            1143
                        ],
                        "page_id": 14
                    }
                ],
                "content": "Thomas Fahringer (Member, IEEE) received the\nPhD degree from the Vienna University of Technol-\nogy in 1993. He has been a full professor of com-\nputer science with the Institute of Computer Science,\nUniversity of Innsbruck, Austria, since 2003. His\nmain research interests include software architectures, programming paradigms, compiler technology,\nperformance analysis, and prediction for parallel and\ndistributed systems.",
                "description": null,
                "id": 297,
                "type": "text"
            },
            {
                "bbox": [
                    {
                        "coord": [
                            528,
                            1011,
                            631,
                            1162
                        ],
                        "page_id": 14
                    }
                ],
                "content": null,
                "description": "A middle-aged man with short, graying hair smiles while wearing a dark suit and tie.",
                "id": 298,
                "type": "figure"
            }
        ],
        "pages": [
            {
                "id": 0,
                "image_uri": null
            },
            {
                "id": 1,
                "image_uri": null
            },
            {
                "id": 2,
                "image_uri": null
            },
            {
                "id": 3,
                "image_uri": null
            },
            {
                "id": 4,
                "image_uri": null
            },
            {
                "id": 5,
                "image_uri": null
            },
            {
                "id": 6,
                "image_uri": null
            },
            {
                "id": 7,
                "image_uri": null
            },
            {
                "id": 8,
                "image_uri": null
            },
            {
                "id": 9,
                "image_uri": null
            },
            {
                "id": 10,
                "image_uri": null
            },
            {
                "id": 11,
                "image_uri": null
            },
            {
                "id": 12,
                "image_uri": null
            },
            {
                "id": 13,
                "image_uri": null
            },
            {
                "id": 14,
                "image_uri": null
            }
        ]
    },
    "error_status": null,
    "metadata": {
        "file_metadata": null,
        "id": "bc056f72-7e81-4145-967f-648399816202",
        "version": "2.0"
    }
}